---
layout: page
title: Mathematical Economics
description: Dynamic models of policy, learning, and equilibrium.
img: assets/img/mathecon.jpg
importance: 1
category: work
related_publications: true
---
<style>
.highlight-box {
  background-color: #f9f9f9;
  border-left: 4px solid #004080;
  padding: 0.8em 1em;
  border-radius: 6px;
  margin: 1em 0;
}

.section-intro p {
  margin-bottom: 0.6em;
}

.quote-block {
  margin: 0.8em 0;
  padding-left: 1em;
  border-left: 3px solid #ccc;
  font-style: italic;
  color: #444;
}
</style>

<p class="lead">
I explore how mathematical structure, stochastic dynamics, and learning mechanisms inform policy and equilibrium outcomes in economics.  
My current work follows three connected lines of inquiry:
</p>

<div class="highlight-box">
<ol>
  <li><strong>Dynamic Policy and Enforcement:</strong> Markovian and control-theoretic approaches to modelling innovation, regulation, and patent rent persistence.</li>
  <li><strong>Learning and Strategic Behaviour:</strong> Reinforcement-learning agents and their equilibrium properties in oligopolistic competition.</li>
  <li><strong>Analytic Structure of Dynamics:</strong> Using tools from differential equations and asymptotic analysis to study macroeconomic adjustment.</li>
</ol>
</div>

---

## 1. Patent Valuation under Fragile Institutional Enforcement

In collaboration with **Akila** (B.A. Economics, MSE) and **Prof. Naveen Srinivasan** (MSE),  
this work studies how uncertainty in the enforcement of intellectual property rights affects patent valuation.  
The model employs a **continuous-time Markov process** to capture stochastic transitions between enforcement states and their effect on discounted monopoly rents.

**Paper:**  
<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5552758" target="_blank">
Patent Valuation under Fragile Institutional Enforcement — A Continuous-Time Markov Approach</a>  
_Srikanth Pai, Akila Hariharan, and Naveen Srinivasan (SSRN Working Paper, 2025)_

---

## 2. Oligopoly Equilibrium with Deep Reinforcement Learning Agents

In collaboration with **Tania Mitra Victoria** (B.A. Economics, MSE) and **Dr. Arun Selvan** (Associate Professor, IIT Bombay), this project investigates how oligopolistic firms using modern reinforcement learning algorithms converge—or fail to converge—to classical Nash equilibria.

_The study tests whether DRL agents (policy-gradient, Q-learning) reproduce Cournot or Bertrand equilibria,  
and identifies parameter regions where outcomes diverge, oscillate, or exhibit chaotic dynamics._

---

## 3. Dynamics and Fuchsian Structure in Macroeconomic Models

I have been exploring whether methods from the theory of Fuchsian differential equations and Écalle’s resurgence analysis can offer insight into short-time adjustment dynamics in growth models.  
Preliminary work on the Solow and RCK frameworks showed they are too regular to exhibit interesting singular behaviour, but non-autonomous or stochastic-parameter versions may reveal richer asymptotics.

---
