<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://srikanthbpai.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://srikanthbpai.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-02-19T17:34:19+00:00</updated><id>https://srikanthbpai.github.io/feed.xml</id><title type="html">blank</title><subtitle>Mathematic </subtitle><entry><title type="html">Trigonometry from Differential Equations</title><link href="https://srikanthbpai.github.io/blog/2026/Trigonometry_ODE/" rel="alternate" type="text/html" title="Trigonometry from Differential Equations"/><published>2026-02-18T18:30:00+00:00</published><updated>2026-02-18T18:30:00+00:00</updated><id>https://srikanthbpai.github.io/blog/2026/Trigonometry_ODE</id><content type="html" xml:base="https://srikanthbpai.github.io/blog/2026/Trigonometry_ODE/"><![CDATA[<p>Our education system provides a multitude of choices for a young eager student. One of those choices, I have learnt recently, is called <em>Applied Mathematics</em>. An inspection of the contents shows much of geometry‚Äîtrigonometry, coordinates, vectors, complex numbers‚Äîis removed, but Calculus remains. I say that this decision is very prudent.</p> <p>While students of applied mathematics lament that they have not learnt trigonometry in school, they do not know that Indian school trigonometry is mostly mindless algebra and very boring. However, the basic ideas surrounding its geometric meaning are very important for Fourier series and any student of science who wants to model periodic phenomena‚Äîespecially macroeconomists passionate about understanding the business cycle.</p> <p>I have written this note for my students who have taken applied mathematics. These students are extremely lucky, since learning trigonometric functions using differential equations is an absolute delight. When I was young, I was spoiled by the geometric route, and the differential equation route was confusing.</p> <p>This note states and proves all the basic trigonometric relations starting from a single differential equation and the theorems of calculus. Secondly, it defines œÄ from first principles using an integral and then works out the approximation 3.14. We also end up <em>proving</em> that this number œÄ is the ratio of the circumference to the diameter of <em>any</em> circle in the world!</p> <p>One wonders why I stop at 3.14‚Äîwhy not compute more digits? Well, it is futile to uncover more decimals since it will never end. Basically, œÄ is irrational. Alas, proving its irrationality will take us far afield, but there is a gorgeous proof by Niven that you can look up.</p> <p>I claim no novelty for this plan of attack. A whiff of these ideas is given in Simmons‚Äô text on differential equations, and I suspect 18th century masters were well aware of this route. However, I have filled in the details and directed this exposition. So sit tight and enjoy the ride.</p> <hr/> <h2 id="the-fundamental-differential-equation">The Fundamental Differential Equation</h2> <p>Consider the second-order linear differential equation \(y'' + y = 0.\)</p> <p>This is one of the simplest nontrivial ODEs in mathematics. By the Picard existence-uniqueness theorem, given any initial conditions $y(0) = a$ and $y‚Äô(0) = b$, there exists a unique solution defined for all $x \in \mathbb{R}$.</p> <p>From this single fact‚Äîand nothing else‚Äîwe construct all of trigonometry.</p> <p><strong>Definition.</strong> Let $S(x)$ denote the unique solution to the ODE $y‚Äô‚Äô + y = 0$ satisfying \(S(0) = 0, \quad S'(0) = 1.\) We call $S$ the <em>sine function</em>. Let $C(x) := S‚Äô(x)$ and call it the <em>cosine function</em>.</p> <p><strong>Key observation.</strong> $C(x)$ also satisfies the same ODE with initial conditions $C(0) = 1$ and $C‚Äô(0) = 0$. We have the fundamental derivative relations: \(S'(x) = C(x), \quad C'(x) = -S(x).\)</p> <hr/> <h2 id="the-addition-formulas">The Addition Formulas</h2> <p><strong>Theorem (Addition for Sine).</strong> For all $x, u \in \mathbb{R}$, \(S(x+u) = S(x)C(u) + C(x)S(u).\)</p> <p><em>Proof idea.</em> Fix $u$ and consider $y(x) := S(x+u)$. It satisfies the ODE with initial conditions $y(0) = S(u)$, $y‚Äô(0) = C(u)$. Separately, define $z(x) := S(x)C(u) + C(x)S(u)$. We can verify that $z$ satisfies the same ODE and initial conditions. By uniqueness, $y = z$.</p> <p><strong>Theorem (Addition for Cosine).</strong> For all $x, u \in \mathbb{R}$, \(C(x+u) = C(x)C(u) - S(x)S(u).\)</p> <p><em>Proof.</em> Differentiate the sine addition formula with respect to $x$.</p> <p><strong>Double Angle Formulas.</strong> Setting $u = x$ in the addition formulas gives: \(S(2x) = 2S(x)C(x), \quad C(2x) = C(x)^2 - S(x)^2.\)</p> <hr/> <h2 id="the-pythagorean-identity">The Pythagorean Identity</h2> <p><strong>Theorem.</strong> For all $x \in \mathbb{R}$, \(S(x)^2 + C(x)^2 = 1.\)</p> <p><em>Proof.</em> Multiply the ODE $S‚Äô‚Äò(x) = -S(x)$ by $S(x)$ and $C‚Äô(x) = -S(x)$ by $C(x)$. Adding yields \(S(x)\,S'(x) + C(x)\,C'(x) = 0,\) which means $\frac{d}{dx}[S(x)^2 + C(x)^2] = 0$. Thus $S(x)^2 + C(x)^2$ is constant. At $x = 0$: $S(0)^2 + C(0)^2 = 0 + 1 = 1$.</p> <p>This is where the geometry emerges: not from assumptions, but from the dynamics of the differential equation.</p> <hr/> <h2 id="defining-œÄ-and-the-boundary-values">Defining œÄ and the Boundary Values</h2> <p>We define an auxiliary function \(g(u) := \int_0^u \frac{dt}{\sqrt{1-t^2}} \quad \text{for } u \in (-1, 1).\)</p> <p>This integral converges (though the integrand is unbounded at $u = 1$). We have $g‚Äô(u) = \frac{1}{\sqrt{1-u^2}} &gt; 0$, so $g$ is strictly increasing.</p> <p><strong>Key Lemma.</strong> For all $x$ where $|S(x)| &lt; 1$, we have $g(S(x)) = x$. This follows by differentiating: \(\frac{d}{dx}g(S(x)) = g'(S(x)) \cdot S'(x) = \frac{1}{\sqrt{1-S(x)^2}} \cdot \sqrt{1-S(x)^2} = 1.\)</p> <p><strong>Definition.</strong> Define \(\frac{\pi}{2} := \int_0^1 \frac{dt}{\sqrt{1-t^2}}.\)</p> <p><strong>Theorem (Special Values).</strong> We have $S(\pi/2) = 1$, $S(-\pi/2) = -1$, and $C(\pi/2) = 0$.</p> <table> <tbody> <tr> <td><em>Proof sketch.</em> The key lemma shows that $g(S(x)) = x$ for $</td> <td>S(x)</td> <td>&lt; 1$. Applying at $x = \pi/2$: $g(S(\pi/2)) = \pi/2$. But by definition, $g(1) = \pi/2$. Since $g$ is strictly increasing (hence one-to-one), $S(\pi/2) = 1$. The Pythagorean identity then gives $C(\pi/2)^2 = 0$.</td> </tr> </tbody> </table> <hr/> <h2 id="computing-œÄ-the-dalzell-integral">Computing œÄ: The Dalzell Integral</h2> <p>To compute œÄ rigorously, we use an elegant integral inequality discovered by Dalzell (1944):</p> <p><strong>Lemma (Arctan Integral).</strong> We have \(\int_0^1 \frac{dx}{1+x^2} = \frac{\pi}{4}.\)</p> <p><em>Proof.</em> Substitute $x = \frac{S(u)}{C(u)}$ for $u \in [0, \pi/4]$. Then $\frac{dx}{du} = \frac{1}{C(u)^2}$ and $1 + x^2 = \frac{1}{C(u)^2}$, so the integral becomes $\int_0^{\pi/4} du = \pi/4$.</p> <p><strong>Lemma (Dalzell Integral).</strong> We have \(\int_0^1 \frac{x^4(1-x)^4}{1+x^2}\,dx = \frac{22}{7} - \pi.\)</p> <p><em>Proof.</em> Expand $x^4(1-x)^4 = x^4 - 4x^5 + 6x^6 - 4x^7 + x^8$. Divide by $1+x^2$ using polynomial long division: \(\frac{x^4(1-x)^4}{1+x^2} = x^6 - 4x^5 + 5x^4 - 4x^2 + 4 - \frac{4}{1+x^2}.\)</p> <p>Integrate term by term. The integral of the polynomial part evaluates to $\frac{1}{7} - \frac{2}{3} + 1 - \frac{4}{3} + 4 = \frac{22}{7}$. The integral of $-\frac{4}{1+x^2}$ is $-4 \cdot \frac{\pi}{4} = -\pi$ (by the arctan lemma). Thus the integral equals $\frac{22}{7} - \pi$.</p> <p><strong>Theorem (Bounds on œÄ).</strong> The integral $\int_0^1 \frac{x^4(1-x)^4}{1+x^2}\,dx$ is strictly positive (since the integrand is nonnegative and positive on $(0,1)$). Therefore, \(\pi &lt; \frac{22}{7} \approx 3.142857.\)</p> <p>Since $\frac{22}{7}$ rounds to $3.14$ at two decimal places, we have rigorously proven:</p> <p>[\boxed{\pi \approx 3.14}]</p> <hr/> <h2 id="periodicity-and-angle-formulas">Periodicity and Angle Formulas</h2> <p><strong>Theorem (Periodicity).</strong> Both $S$ and $C$ have period $2\pi$: \(S(x + 2\pi) = S(x), \quad C(x + 2\pi) = C(x).\)</p> <p><strong>Corollary (Supplementary Angles).</strong> For all $x$, \(S(\pi - x) = S(x), \quad C(\pi - x) = -C(x).\)</p> <p><strong>Corollary (Complementary Angles).</strong> For all $x$, \(S(\pi/2 - x) = C(x), \quad C(\pi/2 - x) = S(x).\)</p> <p>These emerge directly from the addition formulas and the special values.</p> <hr/> <h2 id="the-unit-circle-parametrization">The Unit Circle Parametrization</h2> <p><strong>Theorem.</strong> The map $\Phi: \mathbb{R} \to \mathbb{R}^2$ defined by \(\Phi(x) := (C(x), S(x))\) is a continuous bijection from $[0, 2\pi)$ onto the unit circle ${(a,b) : a^2 + b^2 = 1}$, periodic with period $2\pi$.</p> <p>The Pythagorean identity ensures every point lies on the unit circle. Monotonicity and continuity ensure the parametrization covers the entire circle exactly once per period. The parameter $x$ is the arc length measured counterclockwise from $(1, 0)$.</p> <hr/> <h2 id="arc-length-and-circumference">Arc Length and Circumference</h2> <p><strong>Theorem.</strong> The velocity vector of the curve $(C(t), S(t))$ is $(-S(t), C(t))$, which has magnitude \(\sqrt{S(t)^2 + C(t)^2} = 1.\)</p> <p><strong>Corollary (Circumference of Unit Circle).</strong> The circumference is \(\int_0^{2\pi} 1\,dt = 2\pi.\)</p> <p><strong>Theorem (Circumference of Any Circle).</strong> For a circle of radius $r &gt; 0$, the circumference is \(\boxed{2\pi r}.\)</p> <p><em>Proof.</em> The circle is parametrized as $(rC(t), rS(t))$ for $t \in [0, 2\pi)$. The speed is $r \cdot 1 = r$, so the arc length is $\int_0^{2\pi} r\,dt = 2\pi r$.</p> <hr/> <h2 id="conclusion">Conclusion</h2> <p>We have reconstructed all of trigonometry from a single differential equation and the theorems of calculus. We began with $y‚Äô‚Äô + y = 0$, defined $S$ and $C$ by their initial conditions, proved all the major identities (addition formulas, Pythagorean theorem, periodicity), defined œÄ through an integral, and rigorously established that œÄ is the ratio of circumference to diameter for any circle in the world.</p> <p>The geometry did not come first. It emerged from the analysis. This approach is not only rigorous and beautiful‚Äîit is also the path that any student of applied mathematics should take. No diagrams, no appeal to intuition, no mindless memorization of angle rules. Just differential equations, calculus, and the inexorable march of logic.</p> <p>As the 18th century mathematicians knew, and as Simmons has shown, this is the deepest way to understand trigonometry.</p> <hr/>]]></content><author><name></name></author><category term="teaching"/><category term="mathematics"/><category term="trigonometry"/><category term="differential-equations"/><category term="œÄ"/><category term="calculus"/><category term="pedagogy"/><summary type="html"><![CDATA[Deriving all of trigonometry, œÄ, and the circumference formula from a single ODE using calculus alone.]]></summary></entry><entry><title type="html">Predicting Customer Churn Using Logistic Regression</title><link href="https://srikanthbpai.github.io/blog/2025/LogisticRegression/" rel="alternate" type="text/html" title="Predicting Customer Churn Using Logistic Regression"/><published>2025-10-21T13:00:00+00:00</published><updated>2025-10-21T13:00:00+00:00</updated><id>https://srikanthbpai.github.io/blog/2025/LogisticRegression</id><content type="html" xml:base="https://srikanthbpai.github.io/blog/2025/LogisticRegression/"><![CDATA[<p>In today‚Äôs guest post, a B.A. Econ student at MSE, <a href="https://sites.google.com/view/maahika-mathur/">Ms.Maahika Mathur</a> explains the logistic regression problem using the classic <em>Telco Customer Churn</em> dataset. I usually cover this problem in the <em>Probability for GenAI</em> course, co-taught with <a href="https://www.linkedin.com/in/bastyajayshenoy/?originalSubdomain=in">Dr. Ajay Shenoy</a>.<br/> I have a Python notebook that demonstrates both the mathematics and the implementation behind this method. Maahika studied that notebook and offered to write an expository article expanding on it.</p> <div style="text-align:center; margin: 2em 0;"> <iframe src="/assets/pdf/MM_LogisticReg_CustomerChurn.pdf#view=FitH" width="100%" height="800" style="border: 1px solid #ccc; border-radius: 8px;"> </iframe> <p style="font-size: 0.9em; color: #555;"> <em>Maahika Mathur's guest article on Logistic Regression (embedded PDF)</em> </p> </div> <p>In case you‚Äôd like to download and read it at leisure:<br/> <a href="/assets/pdf/MM_LogisticReg_CustomerChurn.pdf">üìÑ Download Maahika‚Äôs illustrated PDF version</a></p>]]></content><author><name>[&quot;Maahika Mathur,&quot;, &quot;Srikanth Pai&quot;]</name></author><category term="professional"/><category term="teaching"/><category term="project"/><category term="logistic-regression"/><category term="customer-churn"/><category term="probability"/><category term="Python"/><summary type="html"><![CDATA[A student guest post on applying logistic regression to telecom churn data.]]></summary></entry><entry><title type="html">Summing up series using Central Limit theorem</title><link href="https://srikanthbpai.github.io/blog/2025/CLTApps/" rel="alternate" type="text/html" title="Summing up series using Central Limit theorem"/><published>2025-10-19T13:00:00+00:00</published><updated>2025-10-19T13:00:00+00:00</updated><id>https://srikanthbpai.github.io/blog/2025/CLTApps</id><content type="html" xml:base="https://srikanthbpai.github.io/blog/2025/CLTApps/"><![CDATA[<p style="text-align:center;"> ü™î ü™î ü™î &nbsp;Happy Deepavali!&nbsp; ü™î ü™î ü™î </p> <p>I wanted to share an unexpected connection that I discovered this morning.<br/> Usually, calculus and analysis are used to prove results about random variables. In this post, we‚Äôll turn that idea on its head ‚Äî we‚Äôll use the Central Limit Theorem to evaluate a purely analytical limit!</p> <p>So I was browsing through <em>Crux Mathematicorum‚Äôs</em> <a href="https://cms.math.ca/wp-content/uploads/2025/10/Wholeissue_51_8-r2.pdf">latest issue</a> and came across this interesting limit problem:</p> <div class="math-block"> <strong>Crux Problem OC750 (pp 377).</strong> <p>Find</p> \[ \lim_{n \to \infty} \sum_{k = n}^{2n} \binom{k - 1}{\,n - 1\,} 2^{-k}. \] </div> <p>Usually <em>Crux</em> does not accept undergraduate-level solutions, so I will discuss one here.</p> <p>It also happens that I am teaching a probability and statistics course right now. One of the fundamental theorems that connects the theory of probability to the practice of statistics is the <em><a href="https://en.wikipedia.org/wiki/Central_limit_theorem">Central Limit Theorem</a></em>. Let me state a simple version of it:</p> <div class="math-block"> <strong>Theorem.</strong> Let \( X_1,X_2,\cdots,X_n \) be a sequence of independent and identically distributed random variables with expectation $\mu$ and variance $\sigma^2$. If \[ S_n := \sum_{i=1}^n X_i, \quad Y_n = \dfrac{S_n - n\mu}{\sqrt{n\sigma^2}}, \] then \[ \lim_{n\to \infty} F_{Y_n}(x) = \int_{-\infty}^{x} \dfrac{e^{-\frac{t^2}{2}}}{\sqrt{2\pi}} \, dt, \] where $F_X$ represents the cdf of $X$. We denote this statement by \(Y_n \xrightarrow{d} N(0,1)\). </div> <hr/> <p>We will solve the Crux problem by identifying the summand as a probability from a classical setup.</p> <div class="math-block"> <strong>Definition.</strong> Let \(S_n\) denote the number of trials required to obtain the \(n\)-th head in a sequence of independent fair coin tosses. Then for \(k \geq n\), \[ \Pr(S_n = k) = \binom{k-1}{\,n-1\,}2^{-k}. \] </div> <p>This distribution is called the <a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution">negative binomial distribution</a> with parameters \((n,1/2)\).</p> <p><em>Proof.</em><br/> Since the \(n\)-th head appears at the \(k\)-th toss, the remaining \(k-1\) tosses must contain exactly \(n-1\) heads.<br/> This chance can be computed using the binomial distribution: \[ \Pr(S_n = k) = \binom{k-1}{\,n-1\,} \left(\frac{1}{2}\right)^{n} \left(\frac{1}{2}\right)^{k-n} = \binom{k-1}{\,n-1\,}2^{-k}. \]</p> <p>Hence our Crux sum can be written as \[ A_n = \sum_{k=n}^{2n} \binom{k-1}{\,n-1\,} 2^{-k} = \Pr(S_n \le 2n), \] that is, the probability that the \(n\)-th head appears by time \(2n\).</p> <p>Now that we have converted the sum to a probability, we can compute the limit using the Central Limit Theorem.<br/> To apply it, we need to express \(S_n\) as a sum of i.i.d. random variables.<br/> Luckily, the negative binomial distribution is exactly such a sum ‚Äî of independent geometric random variables.</p> <hr/> <p>Let‚Äôs recall <a href="https://en.wikipedia.org/wiki/Geometric_distribution">geometric random variables</a></p> <div class="math-block"> <strong>Definition (Geometric random variable).</strong> A random variable \(X\) has the geometric distribution with parameter \(p\) if \[ \Pr(X=k) = (1-p)^{k-1}p, \qquad k = 1,2,\dots \] and it represents the number of trials required for the first success. </div> <p>It has mean \(E[X] = 1/p\) and variance \(\mathrm{Var}(X) = (1-p)/p^2.\) If we define \(X_1, X_2, \dots, X_n\) as i.i.d. geometric\((1/2)\) random variables, then the total number of trials needed to get \(n\) successes is \[ S_n = X_1 + X_2 + \cdots + X_n. \] Note that \(S_n\) is precisely the number of coin tosses required to see exactly \(n\) heads, since \(X_i\) is the interarrival time between the \((i-1)\)th head and the \(i\)th head.</p> <p>Linearity of expectation and variance immediately gives \[ E[S_n] = 2n, \qquad \mathrm{Var}(S_n) = 2n. \]</p> <hr/> <p>Since the random variable \(S_n\) is a <em>sum of i.i.d.</em> geometric\((1/2)\) variables, the Central Limit Theorem implies \[ \frac{S_n - 2n}{\sqrt{2n}} \;\xrightarrow{d}\; N(0,1). \]</p> <p>Thus, for \(Z \sim N(0,1)\), \[ \lim_{n \to \infty}\Pr(S_n \le 2n) = \Pr(Z \le 0) = \tfrac{1}{2}. \]</p> <p>We finally have</p> <div class="math-block"> <p><strong>Conclusion.</strong></p> \[ \lim_{n \to \infty} \sum_{k=n}^{2n} \binom{k-1}{\,n-1\,}2^{-k} = \tfrac{1}{2}. \] </div> <p>So the apparently analytic limit is, in fact, the probability that the \(n\)-th head appears before its expected time.</p> <hr/> <p>As a professor, I will be remiss if I don‚Äôt give my readers a few exercises:</p> <div class="math-block"> <strong>Exercises.</strong> <p>1. Evaluate the following limit:</p> \[ \lim_{n \to \infty} \int_{0}^{n} \frac{x^{n-1} e^{-x}}{(n-1)!}\, dx. \] <p>[Hint: Sum of iid exponentials is the Gamma distribution.]</p> <p>2. Evaluate the following limit:</p> \[ \lim_{n \to \infty} \sum_{k = 0}^{n} e^{-n}\frac{n^k}{k!}. \] <p>[Hint: Sum of iid Poisson random variables is Poisson.]</p> <p>3. Let \(\Gamma(x)\) denote the Gamma function. Evaluate the following limit:</p> \[ \lim_{n \to \infty} \int_{0}^{n} \frac{1}{2^{n/2}\Gamma\!\left(\tfrac{n}{2}\right)} x^{\frac{n}{2}-1} e^{-x/2}\, dx. \] <p>[Hint: Sum of squares of iid standard normals is Chi-square.]</p> <p>4. For a fixed \(p\in(0,1)\), evaluate the limit:</p> \[ \lim_{n\to\infty} \sum_{k=0}^{\lfloor n p\rfloor} \binom{n}{k}\, p^{k}(1-p)^{n - k}. \] <p>[Hint: Sum of iid Bernoulli variables is Binomial.]</p> </div>]]></content><author><name></name></author><category term="Fun"/><category term="CLT"/><category term="Integrals"/><category term="Series"/><summary type="html"><![CDATA[Central limit theorem can be used to compute some series and integrals.]]></summary></entry><entry><title type="html">A measure of risk aversion:Arrow-Pratt Index</title><link href="https://srikanthbpai.github.io/blog/2025/RiskAversion/" rel="alternate" type="text/html" title="A measure of risk aversion:Arrow-Pratt Index"/><published>2025-10-02T13:00:00+00:00</published><updated>2025-10-02T13:00:00+00:00</updated><id>https://srikanthbpai.github.io/blog/2025/RiskAversion</id><content type="html" xml:base="https://srikanthbpai.github.io/blog/2025/RiskAversion/"><![CDATA[<blockquote> <p>‚ÄúUncertainty must be taken in a sense radically distinct from the familiar notion of Risk, from which it has never been properly separated ‚Ä¶ a measurable uncertainty, or ‚Äòrisk‚Äô proper ‚Ä¶ is so far different from an unmeasurable one that it is not in effect an uncertainty at all.‚Äù ‚Äî Frank H. Knight, <em>Risk, Uncertainty and Profit</em> (1921)</p> </blockquote> <p>Everyday life is filled with events whose outcomes cannot be predicted in advance: a medical emergency, a crop failure, a sudden financial crash. Insurance exists to handle such exposure. By paying a premium, households and firms transfer the consequences of an adverse event to an insurer. The premium is the price of protection, and the excess above the actuarially fair value (the expected loss) records how much the individual is willing to pay to avoid volatility.</p> <p>Knight‚Äôs distinction is useful here. Risk refers to situations with well-defined probabilities, as in coin tosses or actuarial tables. Uncertainty refers to situations where probabilities are not even defined. Insurance theory, and the mathematics that follows, lies on the side of risk. A gamble is a random variable with a known distribution, and the central question is: how much will an individual pay to remove it?</p> <p>To study this systematically, we adopt the von Neumann‚ÄìMorgenstern (vNM) framework. An agent is assumed to have a preference ordering over gambles. If these preferences satisfy the vNM axioms, there exists a utility function $u$ such that lotteries are ranked by their expected utility $\mathbb{E}[u(X)]$. Crucially, $u$ is unique only up to a positive affine transformation $v(x)=au(x)+b$. Any meaningful measure of risk aversion must therefore be invariant under such transformations.</p> <p>This immediately rules out naive candidates such as $u‚Äô‚Äô(w)$ or <a href="https://en.wikipedia.org/wiki/Curvature#Graph_of_a_function">geometric curvature</a>, which change under rescaling. The correct object is the Arrow‚ÄìPratt index, \[r(w) = -\frac{u‚Äô‚Äô(w)}{u‚Äô(w)}.\] It is dimensionless, invariant under affine transformations, and arises directly as the leading-order premium per unit variance of a small gamble. In the remainder of this post, we derive this result carefully, work through examples, and reflect on why this ‚Äúeconomic curvature‚Äù has become the standard measure of risk aversion.</p> <hr/> <h3 id="precise-setup">Precise setup</h3> <p>Let start with a simple example to illustrate the ideas that are about to come.</p> <p>Consider a gamble that pays Rs. 2000/- with probability $1/2$ and Rs. 0/- with probability $1/2$. Then $\mathbb{E}[X]=1000$.</p> <ul> <li>A risk-neutral agent demands no premium: $\pi=0$.</li> <li>A risk-averse agent might accept only Rs. 800/- for sure; in this case the agent is willing to forgo Rs. 200/- to avoid uncertainty. We will say that the risk premium is 200 rupees.</li> </ul> <p>Now we get on with the math. Let $(\Omega,\mathcal{F},P)$ be a probability space, and let $X:\Omega\to\mathbb{R}$ be a random payoff. An agent with initial wealth $w$ evaluates outcomes through a utility function $u:\mathbb{R}\to\mathbb{R}$, continuous, strictly increasing, and differentiable.</p> <p>The agent faces two options:</p> <ol> <li><em>Risky option:</em> receive the random payoff $w + X$.</li> <li><em>Certain option:</em> receive the fixed payoff $w + c$ .</li> </ol> <p>Indifference between these two options is expressed by \[ \mathbb{E}[u(w+X)] = u(w+c). \]</p> <p>The value $c$ solving this equation is called the certainty equivalent of the gamble $X$.</p> <p>The premium $\pi$ that an agent pays over the acturial fair value $\mathbb{E}(X)$ is called the <em>risk premium</em>. Mathematically,<br/> \[ \pi = \mathbb{E}(X)-c \]</p> <p>Substituting the certainty equivalent into the definition of the premium yields the fundamental equation characterizing the risk premium. We make this our definition of risk premium following <a class="citation" href="#pratt1964risk">(Pratt, 1964)</a>:</p> <div class="math-block"> <strong>Definition (Risk premium).</strong> The risk premium $\pi$, associated to a gamble \(X\), of an agent with with wealth \(w\) and utility \(u\), is given by the following equation: \[ \mathbb{E}[u(w+X)] \;=\; u\!\big(w+\mathbb{E}[X]-\pi\big). \] </div> <p>We can show that $\pi$ exists and is unique if we make standard assumptions.</p> <div class="math-block"> <strong>Proposition.</strong> If \( u \) is a concave continuous increasing function then for any real $w$ and random variable $X$ there exists a unique positive real number $\pi$ such that \[ \mathbb{E}[u(w+X)] \;=\; u\!\big(w+\mathbb{E}[X]-\pi\big). \] </div> <div class="math-block proof"> <strong>Proof.</strong> By Jensen's inequality for concave functions \(u\), \[\mathbb{E}(u\left(w+X\right)) &lt; u\left(w+\mathbb{E}(X)\right).\] Since the $u$ is continuous, there must exist a real number \(\pi\) so that \[\mathbb{E}(u\left(w+X\right)) = u\left(w+\mathbb{E}(X)-\pi\right).\] Further $\pi$ unique since the function is increasing.‚àé </div> <h4 id="risk-in-the-context-of-insurance">Risk in the context of insurance</h4> <p>In insurance terminology, the <em>loading ratio</em> (or <em>loading factor</em>) is defined as the multiple by which the <em>gross premium</em> exceeds the <em>actuarially fair premium</em> (i.e. expected losses). In other words,<br/> \[ \text{loading ratio} = \frac{\text{gross premium}}{\text{expected loss}}. \]<br/> This captures all extra costs insurers build in ‚Äî administrative expenses, underwriting, profit margins, risk margins, etc.</p> <p>Empirically, loading ratios vary quite a lot across sectors. In health insurance, administrative loadings often add <strong>5% to 20%</strong> above expected claims in competitive markets (<a href="https://link.springer.com/article/10.1007/s10198-022-01436-y">Springer Health Econ, 2022</a>). In specialty or retail markets (like travel insurance, warranty contracts), loadings may be far more extreme, sometimes multiple times the fair value (<a href="https://www.partnerslife.co.nz/news-and-views/what-are-premium-loadings">Partners Life, NZ</a>). In property/casualty lines, loss ratios (i.e. claims √∑ premiums) often lie in the 70‚Äì99% range, leaving the balance for loadings and profit (<a href="https://en.wikipedia.org/wiki/Loss_ratio">Wikipedia: Loss ratio</a>).</p> <p>In India, loading ratios are often significant. For example, health insurers routinely impose <em>loading charges</em> on individuals with pre-existing conditions, age, or unhealthy behavior as an extra amount over the base premium (<a href="https://www.acko.com/health-insurance/loading/">Acko Health Insurance</a>). In the non-life sector, motor insurance sometimes runs at very high combined ratios, with reports that the combined ratio might approach <strong>200 %</strong> in some years (i.e. gross premium double the expected claims + expenses) (<a href="https://www.business-standard.com/article/finance/motor-insurance-combined-ratios-may-touch-200-by-end-of-fy15-114040100041_1.html">Business Standard</a>). In the motor third-party (TP) segment, it is observed that while motorcycle TP contributes 15.5 % of TP premium, its share of incurred TP claims is 21.1 %, indicating a mismatch of premium to claims across classes (<a href="https://www.gicouncil.in/yearbook/2021-22/indian-non-life-insurance-industry-analysis/section-04-segmentwise-business-highlights/motor-third-party-tp/">GIC Council Yearbook 2021-22</a>).</p> <p>Thus in India, it is not unusual for gross premiums to be <em>1.5√ó, 2√ó, or even higher multiples</em> of actuarial expected loss, depending on line and risk class.</p> <p>Now lets a see an example calculation assuming a concave utility function.</p> <p><em>Example:</em></p> <p>Consider an agent with a wealth \(w = 10\) lakh rupees and utility function \(u(c) = \sqrt{c}\). The agent faces a small risk: with probability \(0.01\) a loss of \(10{,}000\) occurs, and with probability \(0.99\) no loss occurs. The actuarially fair premium for this gamble is \(0.01 \times 10{,}000 = 100\).</p> <p>With no insurance, expected utility is<br/> \[ \mathbb{E}[u(w+X)] = 0.99\sqrt{10{,}00{,}000} + 0.01\sqrt{9{,}90{,}000} \approx 999.95. \]</p> <p>With insurance, certain wealth is \(9{,}99{,}900 - \pi\), giving utility<br/> \[ u(9{,}99{,}900 - \pi) = \sqrt{9{,}99{,}900 - \pi}. \]</p> <p>Equating the two expressions,<br/> \[ \sqrt{9{,}99{,}900 - \pi} \approx 999.95, \] which solves to \(\pi \approx 95\).</p> <p>Hence the household would pay about ‚Çπ195 in total (‚Çπ100 fair value plus a ‚Çπ95 risk premium) to eliminate the 1% risk of losing ‚Çπ10,000. In this example, the ratio of willingness-to-pay to the actuarially fair premium is<br/> \[ \frac{195}{100} = 1.95. \]<br/> In this example, the household‚Äôs willingness-to-pay ratio is 1.95, meaning they would pay nearly double the actuarially fair premium. In a perfectly competitive and frictionless insurance market, such willingness-to-pay would put an upper bound on the loading ratio insurers could sustain.</p> <p>In the previous example, the square root utility function was arbitrary. The exact value of the risk premium is certainly sensitive to the utility function used. Thus if we are interested in computing premiums, we are forced to contemplate the design of utility functions.</p> <p>In order to understand such a design, we look at a measure of local risk aversion. The pertinent question now is: <em>how much premium will the agent pay if the gamble is small compared to their wealth?</em></p> <p>We talk about small gambles by introducing a scale factor. We scale a gamble by a factor \(t\) and study the risk premium \(\pi(t)\) defined by</p> <p>\[ u(w-\pi(t)) \;=\; \mathbb{E}[u(w+tX)]. \]</p> <hr/> <div class="math-block"> <strong>Proposition (Leading-order risk premium).</strong> Let \(u \in C^{3}\) with \(u'(w) &gt; 0\). Let \(X\) satisfy \(\mathbb{E}[X] = 0\) and \(\mathrm{Var}(X) = \sigma^{2} &lt; \infty\). Define \(\pi(t)\) by \[ u(w-\pi(t)) = \mathbb{E}[u(w+tX)]. \] Then, as \(t \to 0\), \[ \pi(t) \;=\; \tfrac12\,r(w)\,\sigma^{2}\,t^{2} + o(t^{2}), \qquad\text{where}\qquad r(w) = -\,\frac{u''(w)}{u'(w)}. \] </div> <div class="math-block proof"> <strong>Proof.</strong> Taylor-expand the left-hand side at \(w\): \[ u(w-\pi) = u(w) - u'(w)\pi + \tfrac12 u''(w)\pi^{2} + O(\pi^{3}). \] Expand the right-hand side inside the expectation and take expectations: \[ u(w+tX) = u(w) + u'(w)tX + \tfrac12 u''(w)t^{2}X^{2} + O(t^{3}|X|^{3}), \] so that \[ \mathbb{E}[u(w+tX)] = u(w) + \tfrac12 u''(w)\sigma^{2}t^{2} + O(t^{3}\,\mathbb{E}|X|^{3}), \] using \(\mathbb{E}[X] = 0\). Equating both sides and canceling \(u(w)\) gives \[ -\,u'(w)\pi(t) + \tfrac12 u''(w)\pi(t)^{2} + O(\pi(t)^{3}) = \tfrac12 u''(w)\sigma^{2}t^{2} + O(t^{3}). \] Since the right-hand side is \(O(t^{2})\), we must have \(\pi(t) = O(t^{2})\); hence \(\pi(t)^{2} = O(t^{4}) = o(t^{2})\). Neglecting higher-order terms, \[ -\,u'(w)\pi(t) = \tfrac12 u''(w)\sigma^{2}t^{2} + o(t^{2}), \] which simplifies to \[ \pi(t) = \tfrac12\left(-\frac{u''(w)}{u'(w)}\right)\sigma^{2}t^{2} + o(t^{2}) = \tfrac12\,r(w)\,\sigma^{2}t^{2} + o(t^{2}).‚àé \] </div> <p>So the relation between local risk aversion $r(w)$, volatility of the gamble $\sigma^2t^2$ and risk premium $\pi$ is \[ \text{local risk aversion} = \dfrac{2\times \text{ risk premium}}{\text{volatility of the gamble }} \]</p> <p>The definition of $r(w)$ in terms of utility allows us to design utility function by solving odes.</p> <p><em>Example 1:</em> If $r(w)=0$ for all $w$, then ${u‚Äô‚Äô}(w)=0$. Thus $u(w)$ is linear. This is the risk neutral case. Also note that if $u$ is concave, increasing then $r(w) &gt; 0$ which is usually the risk averse case.</p> <p><em>Example 2:</em> Now lets work out the constant risk aversion case. For some real number $c$, we have $r(w) = c$ for all $w$. In this case we can solve the differential equation \[{u‚Äô‚Äô}(w) = -cu‚Äô(w)\] by integrating twice. We get $u(w) = -e^{-cw}/c$ upto scaling. This is a concave utility function which remains equivalent under shifts of wealth. So at any value of wealth, the risk premium must be the same. This is true from the theorem above since r is constant.</p> <p><em>Example 3:</em> A famous example is when $wr(w) = \gamma$. Assuming $\gamma \neq 1, \gamma &gt;0$, the solution to \[w{u‚Äô‚Äô}(w) = -\gamma u‚Äô(w)\] is given by \[u(w) = \dfrac{w^{(1-\gamma)}-1}{1-\gamma}.\] This utility function is called constant relative risk aversion (CRRA) function. There is a way to justify the CRRA name but I will not explain it here. If you meet me on the street, you can ask me :)</p> <p>If utility is rescaled as $\tilde u = a u + b$ with $a&gt;0$, then \[ -\,\frac{\tilde u‚Äô‚Äô}{\tilde u‚Äô} = -\,\frac{u‚Äô‚Äô}{u‚Äô}, \] so the Arrow‚ÄìPratt index is unchanged. The measure of risk aversion depends only on preferences, not units. This property ensures that the measure of risk aversion does not depend on arbitrary rescalings or shifts of utility, but only on the underlying preference structure. In other words, $r(w)$ captures a genuine feature of risk preferences rather than a mere artifact of normalization.</p> <p>We began with the everyday intuition of paying insurance premiums to reduce uncertainty. By formalizing this as a utility maximization problem, we derived the <strong>risk premium</strong> $\pi$ as the key measure of aversion to risk. For small gambles, the <strong>Arrow‚ÄìPratt index</strong> $r(w)$ precisely quantifies the willingness to pay per unit of variance.</p> <hr/> <h2 class="bibliography">1964</h2> <ol class="bibliography"><li><div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="pratt1964risk" class="col-sm-8"> <div class="title">Risk Aversion in the Small and in the Large</div> <div class="author"> John W. Pratt </div> <div class="periodical"> <em>Econometrica</em>, 1964 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> ]]></content><author><name></name></author><category term="professional"/><category term="teaching"/><category term="project"/><category term="utility"/><category term="risk-aversion"/><category term="Arrow-Pratt"/><summary type="html"><![CDATA[On risk premium computations and the resulting measure of local risk aversion .]]></summary></entry><entry><title type="html">Copulas - the art of avoiding marginal distributions!</title><link href="https://srikanthbpai.github.io/blog/2025/Copulas/" rel="alternate" type="text/html" title="Copulas - the art of avoiding marginal distributions!"/><published>2025-05-26T15:59:00+00:00</published><updated>2025-05-26T15:59:00+00:00</updated><id>https://srikanthbpai.github.io/blog/2025/Copulas</id><content type="html" xml:base="https://srikanthbpai.github.io/blog/2025/Copulas/"><![CDATA[<p>The simplest decision problem is forecasting the value of one variable in terms of another. We will focus on the relationship between stock prices and index prices, usually called a market model, in this blogpost. Our job as academics is to tease out the precise meaning of the word ‚Äòrelation‚Äô.</p> <p>Consider an imaginary table of stock price vs index price:</p> <table> <thead> <tr> <th>Stock Price (X)</th> <th>Index Price (Y)</th> </tr> </thead> <tbody> <tr> <td>2</td> <td>45</td> </tr> <tr> <td>2</td> <td>52</td> </tr> <tr> <td>2</td> <td>48</td> </tr> <tr> <td>3</td> <td>52</td> </tr> <tr> <td>3</td> <td>60</td> </tr> <tr> <td>4</td> <td>65</td> </tr> <tr> <td>4</td> <td>68</td> </tr> <tr> <td>4</td> <td>70</td> </tr> <tr> <td>5</td> <td>68</td> </tr> <tr> <td>5</td> <td>75</td> </tr> <tr> <td>5</td> <td>80</td> </tr> <tr> <td>6</td> <td>80</td> </tr> </tbody> </table> <blockquote> <p>How do we find a relation between the two variables?</p> </blockquote> <h3 id="from-functional-relations-to-distributions">From Functional Relations to Distributions</h3> <p>The figure below illustrates three types of relationships we can observe:</p> <ol> <li>Ideally, we would love to get a functional relation $Y=h(X)$, i.e. a unique value of $Y$ for each value of $X$. The economists favorite tool ‚Äòlinear regression‚Äô is popular because who doesn‚Äôt love functional relations. Linear is easy so it sweetens the pot!</li> <li>However, in practice, when we collect data and stare at the table, we usually get multivalued function, i.e. $h(X)$ can be a set of values.</li> <li>When sufficient number of data collection experiments are repeated, the data usually has more information: we can keep track of the multiplicity of values. So we get a ‚Äòdistribution‚Äô!</li> </ol> <figure style="text-align: center;"> <img src="/assets/img/fun2dist.png" alt="Description" style="width: 70%; height: auto;"/> <figcaption style="margin-top: 0.5em; font-size: 0.9em; color: #666;"> <em>Figure: Three forms of relations.</em> </figcaption> </figure> <p>In summary, we may view a conditional distribution $\Pr\{Y=y \mid X=x\}$ as a ‚Äòstatistical function‚Äô. For every input value of $x$, it gives us a distribution of $y$ values instead of a single value. Traditionally, in probability theory, conditional distributions are computed using joint distributions of $(X,Y)$. Information about the marginal distributions is stored within the joint distribution.</p> <h3 id="copulas-capturing-dependence-without-marginals">Copulas: Capturing Dependence Without Marginals</h3> <p>The aim of this blogpost is to motivate an interesting form of ‚Äòjoint distribution‚Äô, called ‚ÄòCopula‚Äô, that forgets the marginal distribution information! Think of it as analogous to a linear relation after converting both the variables to percentages. So its like a relation between normalized variables.</p> <p>This becomes especially useful when there is no consensus on the marginal distributions of the variables involved. A good example is the distribution of daily stock returns. These are often assumed to follow a normal distribution, but in reality, large deviations (extreme returns) occur far too frequently for that assumption to hold. Recognizing this, Mandelbrot (in @mandelbrot1963variation) and Fama (in @fama1965behavior) later proposed using L√©vy-stable distributions as more appropriate alternatives.</p> <blockquote> <p>If distribution of returns is controversial, can we study market models independent of such assumptions?</p> </blockquote> <p>YES! We can use <em>copulas</em>.</p> <p>The idea of copula is motivated by a cute mathematical observation.</p> <div class="math-block"> <strong>Proposition.</strong> Let \( X \) be a random variable with a continuous CDF \( F \) and let \( Y = F(X). \) Then \(Y\) is uniformly distributed on the interval \([0,1].\) </div> <div class="math-block proof"> <strong>Proof.</strong> Since \( F \) is continuous and increasing, it is invertible. By properties of cdf, we know that \(0 &lt; Y &lt; 1.\) Consider a real number \(y\) such that \(0 &lt; y &lt; 1\), let us compute the cdf of \(Y: \) $$ \begin{align} F_Y(y) &amp;= \Pr\{Y \leq y\} \\ &amp;= \Pr\{F(X) \leq y\} \\ &amp;= \Pr\{X \leq F^{-1}(y)\} \\ &amp;= F(F^{-1}(y)) \\ &amp;= y \end{align} $$ Hence, \( Y \sim \text{Uniform}(0,1) \). ‚àé </div> <p>So we have a universal method to transform a random variable with known distribution into a uniform random variable! Now suppose we have two variables $X,Y$ with marginal cdfs $F_X,F_Y$, the joint cdf of the uniform random variables $U_X = F_X(X), U_Y=F_Y(Y)$ is called the <em>copula</em> of $X,Y$ (see @sklar1959).</p> <div class="math-block"> <strong>Definition.</strong> Let $X,Y$ be two random variables with marginal cdfs $F_X,F_Y$. Then the copula $C(u,v)$ is defined as \[ C(u,v) = \Pr\left\{X \leq F_X^{-1}(u),Y \leq F_Y^{-1}(v)\right\},\] for $0 &lt; u,v &lt; 1$. </div> <p>The copula has the following cool features:</p> <ol> <li>The copula is a joint distribution of two uniform random variables. The marginal distribution of $X,Y$ is lost and cannot be recovered from the copula.</li> <li>If $X,Y$ are independent, then copula $C(u,v) = uv$. If they are completely dependent, say $X=Y$, then $C(u,v) = \text{min}\{u,v\}$. Thus copula still tracks the relation between variables even though the marginal information is lost.</li> <li>Sklar‚Äôs theorem allows you to build a joint cdf by assembling a copula and a pair of marginal distributions!</li> </ol> <p>In finance, the controversial question of whether daily returns of stock prices are normally distributed can be side stepped with copulas. We can focus on a copula based market model where we estimate the copula of stock return and index return. The conditional distribution of stock crash given that the market has crashed is called the ‚Äòmarket crash risk‚Äô. <a href="https://www.mse.ac.in/faculty/ekta/">Dr. Selarka</a>, my MA student Amritha, and I estimated the market crash risk for Nifty50 and it forms the main part of Amritha‚Äôs dissertation. Amritha has written python modules for copula estimation following the ideas in Chabi-Yo <em>et. al.</em> and I leave you with pretty pictures from her dissertation. If you are curious, read it and let us know your comments.</p> <figure style="text-align: center;"> <img src="/assets/img/copulas-amritha.png" alt="Description" style="width: 50%; height: auto;"/> <figcaption style="margin-top: 0.5em; font-size: 0.9em; color: #666;"> <em>Figure: If you are curious about these pretty pictures, read Amritha's dissertation. </em> </figcaption> </figure>]]></content><author><name></name></author><category term="professional"/><category term="teaching"/><category term="project"/><category term="probability"/><category term="stocks"/><summary type="html"><![CDATA[Market crash risk without marginal information?]]></summary></entry><entry><title type="html">Andre‚Äôs Reflection Trick</title><link href="https://srikanthbpai.github.io/blog/2024/Andres-reflection-trick/" rel="alternate" type="text/html" title="Andre‚Äôs Reflection Trick"/><published>2024-09-29T15:59:00+00:00</published><updated>2024-09-29T15:59:00+00:00</updated><id>https://srikanthbpai.github.io/blog/2024/Andres-reflection-trick</id><content type="html" xml:base="https://srikanthbpai.github.io/blog/2024/Andres-reflection-trick/"><![CDATA[<p>Here‚Äôs an interesting problem related to voting and ballot counts:</p> <p><strong>Suppose A and B win p and q votes respectively in an election with p &gt; q. While counting the ballots, what is the probability that A always remains ahead of B throughout the count?</strong></p> <p>The problem is recast graphically and then Andre‚Äôs beautiful insight solves the problem quickly. Watch it explained in this video:</p> <iframe style="display: block; margin: auto;" width="560" height="315" src="https://www.youtube.com/embed/ebKPaj9Pj6s?si=2NHw--F9A2G60vwM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>]]></content><author><name></name></author><category term="Cool"/><category term="math"/><category term="Voting"/><category term="problems"/><category term="Probability"/><summary type="html"><![CDATA[Probability problem on vote count.]]></summary></entry></feed>