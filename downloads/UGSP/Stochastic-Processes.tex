% --- LaTeX Lecture Notes Template - S. Venkatraman ---

% --- Set document class and font size ---

\documentclass[letterpaper, 12pt]{article}

% --- Package imports ---

% Extended set of colors
\usepackage[dvipsnames]{xcolor}

\usepackage{
  amsmath, amsthm, amssymb, mathtools, dsfont, units,          % Math typesetting
  graphicx, wrapfig, subfig, float,                            % Figures and graphics formatting
  listings, color, inconsolata, pythonhighlight,               % Code formatting
  fancyhdr, sectsty, hyperref, enumerate, enumitem, framed }   % Headers/footers, section fonts, links, lists

% lipsum is just for generating placeholder text and can be removed
\usepackage{hyperref, lipsum} 

% --- Fonts ---

\usepackage{newpxtext, newpxmath, inconsolata}

% --- Page layout settings ---

% Set page margins
\usepackage[left=1in, right=1in, top=1.0in, bottom=.9in, headsep=.2in, footskip=0.35in]{geometry}

% Anchor footnotes to the bottom of the page
\usepackage[bottom]{footmisc}

% Set line spacing
\renewcommand{\baselinestretch}{1.2}

% Set spacing between paragraphs
\setlength{\parskip}{1.3mm}

% Allow multi-line equations to break onto the next page
\allowdisplaybreaks

% --- Page formatting settings ---

% Set image captions to be italicized
\usepackage[font={it,footnotesize}]{caption}

% Set link colors for labeled items (blue), citations (red), URLs (orange)
\hypersetup{colorlinks=true, linkcolor=RoyalBlue, citecolor=RedOrange, urlcolor=ForestGreen}

% Set font size for section titles (\large) and subtitles (\normalsize) 
\usepackage{titlesec}
\titleformat{\section}{\large\bfseries}{{\fontsize{19}{19}\selectfont\textreferencemark}\;\; }{0em}{}
\titleformat{\subsection}{\normalsize\bfseries\selectfont}{\thesubsection\;\;\;}{0em}{}

% Enumerated/bulleted lists: make numbers/bullets flush left
%\setlist[enumerate]{wide=2pt, leftmargin=16pt, labelwidth=0pt}
\setlist[itemize]{wide=0pt, leftmargin=16pt, labelwidth=10pt, align=left}

% --- Table of contents settings ---

\usepackage[subfigure]{tocloft}

% Reduce spacing between sections in table of contents
\setlength{\cftbeforesecskip}{.9ex}

% Remove indentation for sections
\cftsetindents{section}{0em}{0em}

% Set font size (\large) for table of contents title
\renewcommand{\cfttoctitlefont}{\large\bfseries}

% Remove numbers/bullets from section titles in table of contents
\makeatletter
\renewcommand{\cftsecpresnum}{\begin{lrbox}{\@tempboxa}}
\renewcommand{\cftsecaftersnum}{\end{lrbox}}
\makeatother

% --- Set path for images ---

%\graphicspath{{Images/}{../Images/}}

% --- Math/Statistics commands ---

% Add a reference number to a single line of a multi-line equation
% Usage: "\numberthis\label{labelNameHere}" in an align or gather environment
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

% Shortcut for bold text in math mode, e.g. $\b{X}$
\let\b\mathbf

% Shortcut for bold Greek letters, e.g. $\bg{\beta}$
\let\bg\boldsymbol

% Shortcut for calligraphic script, e.g. %\mc{M}$
\let\mc\mathcal

% \mathscr{(letter here)} is sometimes used to denote vector spaces
\usepackage[mathscr]{euscript}

% Convergence: right arrow with optional text on top
% E.g. $\converge[p]$ for converges in probability
\newcommand{\converge}[1][]{\xrightarrow{#1}}

% Weak convergence: harpoon symbol with optional text on top
% E.g. $\wconverge[n\to\infty]$
\newcommand{\wconverge}[1][]{\stackrel{#1}{\rightharpoonup}}

% Equality: equals sign with optional text on top
% E.g. $X \equals[d] Y$ for equality in distribution
\newcommand{\equals}[1][]{\stackrel{\smash{#1}}{=}}

% Normal distribution: arguments are the mean and variance
% E.g. $\normal{\mu}{\sigma}$
\newcommand{\normal}[2]{\mathcal{N}\left(#1,#2\right)}

% Uniform distribution: arguments are the left and right endpoints
% E.g. $\unif{0}{1}$
\newcommand{\unif}[2]{\text{Uniform}(#1,#2)}

% Independent and identically distributed random variables
% E.g. $ X_1,...,X_n \iid \normal{0}{1}$
\newcommand{\iid}{\stackrel{\smash{\text{iid}}}{\sim}}

% Sequences (this shortcut is mostly to reduce finger strain for small hands)
% E.g. to write $\{A_n\}_{n\geq 1}$, do $\bk{A_n}{n\geq 1}$
\newcommand{\bk}[2]{\{#1\}_{#2}}

% Math mode symbols for common sets and spaces. Example usage: $\R$
\newcommand{\R}{\mathbb{R}} % Real numbers
\newcommand{\C}{\mathbb{C}} % Complex numbers
\newcommand{\Q}{\mathbb{Q}} % Rational numbers
\newcommand{\Z}{\mathbb{Z}} % Integers
\newcommand{\N}{\mathbb{N}} % Natural numbers
\newcommand{\F}{\mathcal{F}}  % Calligraphic F for a sigma algebra
\newcommand{\El}{\mathcal{L}} % Calligraphic L, e.g. for L^p spaces

% Math mode symbols for probability
\newcommand{\pr}{\mathbb{P}}  % Probability measure
\newcommand{\E}{\mathbb{E}} % Expectation, e.g. $\E(X)$
\newcommand{\var}{\text{Var}} % Variance, e.g. $\var(X)$
\newcommand{\cov}{\text{Cov}} % Covariance, e.g. $\cov(X,Y)$
\newcommand{\corr}{\text{Corr}} % Correlation, e.g. $\corr(X,Y)$
\newcommand{\B}{\mathcal{B}}  % Borel sigma-algebra

% Other miscellaneous symbols
\newcommand{\tth}{\text{th}}  % Non-italicized 'th', e.g. $n^\tth$
\newcommand{\Oh}{\mathcal{O}} % Big-O notation, e.g. $\O(n)$
\newcommand{\1}{\mathds{1}} % Indicator function, e.g. $\1_A$

% Additional commands for math mode
\DeclareMathOperator*{\argmax}{argmax}    % Argmax, e.g. $\argmax_{x\in[0,1]} f(x)$
\DeclareMathOperator*{\argmin}{argmin}    % Argmin, e.g. $\argmin_{x\in[0,1]} f(x)$
\DeclareMathOperator*{\spann}{Span}   % Span, e.g. $\spann\{X_1,...,X_n\}$
\DeclareMathOperator*{\bias}{Bias}    % Bias, e.g. $\bias(\hat\theta)$
\DeclareMathOperator*{\ran}{ran}      % Range of an operator, e.g. $\ran(T) 
\DeclareMathOperator*{\dv}{d\!}     % Non-italicized 'with respect to', e.g. $\int f(x) \dv x$
\DeclareMathOperator*{\diag}{diag}    % Diagonal of a matrix, e.g. $\diag(M)$
\DeclareMathOperator*{\trace}{trace}    % Trace of a matrix, e.g. $\trace(M)$
\DeclareMathOperator*{\supp}{supp}    % Support of a function, e.g., $\supp(f)$

% Numbered theorem, lemma, etc. settings - e.g., a definition, lemma, and theorem appearing in that 
% order in Lecture 2 will be numbered Definition 2.1, Lemma 2.2, Theorem 2.3. 
% Example usage: \begin{theorem}[Name of theorem] Theorem statement \end{theorem}
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}

% Un-numbered theorem, lemma, etc. settings
% Example usage: \begin{lemma*}[Name of lemma] Lemma statement \end{lemma*}
\newtheorem*{theorem*}{Theorem}
\newtheorem*{proposition*}{Proposition}
\newtheorem*{lemma*}{Lemma}
\newtheorem*{corollary*}{Corollary}
\newtheorem*{definition*}{Definition}
\newtheorem*{example*}{Example}
\newtheorem*{remark*}{Remark}
\newtheorem*{claim}{Claim}
\newtheorem*{axioms*}{Kolmogorov's Axioms}
\newtheorem{exercise}{Exercise}
% --- Left/right header text (to appear on every page) ---

% Do not include a line under header or above footer
\pagestyle{fancy}
\renewcommand{\footrulewidth}{0pt}
\renewcommand{\headrulewidth}{0pt}

% Right header text: Lecture number and title
\renewcommand{\sectionmark}[1]{\markright{#1} }
\fancyhead[R]{\small\textit{\nouppercase{\rightmark}}}

% Left header text: Short course title, hyperlinked to table of contents
\fancyhead[L]{\hyperref[sec:contents]{\small DE13}}

% --- Document starts here ---

\begin{document}

% --- Main title and subtitle ---

\title{DE 13: Stochastic Processes \\[1em]
\normalsize Madras School of Economics}

% --- Author and date of last update ---

\author{\normalsize Srikanth Pai}
\date{\normalsize\vspace{-1ex} Last updated: \today}

% --- Add title and table of contents ---

\maketitle
\tableofcontents\label{sec:contents}

% --- Main content: import lectures as subfiles ---
\newpage
\section*{Preface}

I am a curious person with little knowledge of finance and economics, so I urge the reader to not take my finance/economics ideas seriously. It is essentially a laymanâ€™s view of the subject. I love to learn new ideas, so I will be delighted to be corrected. So, you can always tell me where I am wrong by writing an email or telling me directly if you spot me somewhere at MSE.

The goal of mathematical training is to make ideas precise. So when mathematics is written, the definitions are stated clearly, precise claims are proposed, and then these claims are proved rigorously. A collection of examples usually motivates the questions. The examples are also used to test the claims. It is always worthwhile to study examples that are important to humanity. After all, we all live in this world briefly, so why squabble our precious time and energy on inconsequential examples? I.I.D processes, Markov processes, Martingales and Brownian motions are essential examples of stochastic processes that are widely studied because they arise very often when we look at the world around us. Natural questions about these processes are proposed in this text, and the answers are stated precisely using a theorem-proof format. We will also apply the theorems to many problems and learn to compute efficiently.
\newpage

\section{Fundamentals of Probability}
The primary objective of probability theory is to provide a framework for studying the chances of interesting events that happen in the real world. We view all such interesting phenomena as experiments. Imagine we are studying an experiment that involves chance and we can contemplate the collection of all possible outcomes of the experiment. The plan is to model real life events using {\bf set theory}. A textbook example of an experiment is tossing a coin indefinitely and here is a quick dictionary:

\begin{table}[h]
\begin{tabular}{|l|l|}
 \hline
 \text{\bf English} & \text{\bf Math Translation} \\
 \hline
 \text{Collection of all outcomes} & \text{Sample space} $\Omega$ \\
 \hline
 \text{An outcome is realized/The experiment is performed} &  \text{ Pick }$\omega \in \Omega$ \\
 \hline
 \text{An event E} &  $E$ \text{ is a subset of } $\Omega$\\
 \hline
 \text{An experiment is performed and the event E has occurred}&  \text{ Pick }$\omega \in \Omega$ and $\omega \in E$\\
 \hline
 \text{An event E implies event F}&  $E \subseteq F$\\
 \hline
 \text{The chance of E happening is }$p$ & $\Pr(E) = p$\\
 \hline 
\end{tabular}
\end{table}

In other words, the main actors of the story are {\bf events} and {\bf probability} assigned to every event. In school we learn to add, subtract, and multiply numbers. The rules governing these numbers is called arithmetic, but when the rules are generalized to variables, we call the subject `Algebra'. In the same way there is an associated algebra of manipulating events by forming composite events using simple events. We implement this algebra using algebra of sets. The analog of addition is union, multiplication is intersection and negation is complement (\textit{Don't take the analogy too literally!}). Imagine an experiment has been performed and an outcome has been realized. This means we have picked an element $\omega \in \Omega$. Here is a quick dictionary between composite events and algebra of sets: For a countable collection, $A_1,A_2,\ldots, A_n \ldots $, of subsets,
\begin{table}[h]
\begin{tabular}{|l|l|}
\hline
 \text{Atleast one of the events} $A_i$ happens & $\omega \in A_1 \cup A_2 \cup \ldots \cup A_n \cup \ldots$ \\
 \hline
 \text{All the events } $A_i$ \text{ simultaneously happen } &  $\omega \in A_1 \cap A_2 \cap \ldots \cap A_n \ldots $\\
 \hline
 \text{Event} $A_1$ \text{ has not occurred } &  $\omega \in A_1^c$\\
 \hline 
\end{tabular}
\end{table}

In your first year math course, you were introduced to a new operation: limits! Calculus is founded on the notion of limits of functions and the interactions of limits with algebra of variables. In a similar way, we want to be able to work with limits in probability. So above we have considered the dictionary for countable collection of events. 

It is natural to wish that given basic events, the countable unions, countable intersections and complements of these basic events are also events. This wish leads to the following definition.

\begin{definition}
   Let $\Omega$ be a given set. If $\cal F$ is a collection of subsets of $\Omega$ that are closed under countable unions, countable intersections and complements, then we say $\cal F$ is a $\sigma$ - algebra.
 \end{definition}

The central focus of probability theory is to explore questions of the type: What is the chance associated to an event?
Given a sample space $\Omega$ and any event $E$ in a $\sigma$-algebra $\cal F$, we want to assign a number $\Pr(E)$ that measures the chance that the event $E$ occurs. The assignment of chance to events transforms algebra of manipulating events to the algebra of real numbers. The rules governing the transformations is decreed in the axioms of probability theory:

\begin{definition}
\label{axiom:kolm}
A triple $(\Omega,{\cal F}, \Pr)$, where $\Omega$ is a set, $\cal F$ is a $\sigma$-algebra of subsets and $\Pr:{\cal F} \to \mathbb{R}$ is a function, that satisfy
\begin{enumerate}
\item (Axiom $1$) For any $E$ in $\cal F$, $\Pr(E) \geq 0$.
\item (Axiom $2$)  $\Pr(\Omega) = 1$.
\item (Axiom $3$)  If $A_1,A_2,\ldots A_n\ldots$ in $\cal F$ are a countable or a finite collection of disjoint subsets, then \[\displaystyle \Pr\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} \Pr(A_i).\]
\end{enumerate}
 is called a \textit{probability space.}
\end{definition}

The sample space $\Omega$ represents the collection of all outcomes of an experiment and we can consider it synonymous with the experiment itself. The collection of subsets $\cal F$ represents a collection of interesting events. Finally the function $\Pr$ is called a \emph{probability measure} that measures chances of events. The first axiom states that chances of events is a non-negative number. The second axiom says that any outcome is surely in the sample space. The third axiom states: The chance that atleast one of the events in a countable (or finite) collection of mutually exclusive events occurs is the sum of the chances of individual events. It mimics the principle in geometry ``The total area of the union of disjoint regions is the sum of the areas of its parts.'' Or we can simply remember it as ``the whole is the sum of its parts''.

A few immediate consequences of the axioms:

\begin{enumerate}
\item Let $\phi$ denote the empty set, then $$\Pr(\phi) = 0.$$ 
\textit{Proof:} Apply Axiom 3 to two disjoint sets $A_1=A_2 =\phi$ to get
\begin{align*}
 \Pr(\phi) + \Pr(\phi) &= \Pr(\phi \cup \phi)\\
 \Pr(\phi) + \Pr(\phi) &= \Pr(\phi)\\
\Pr(\phi) &= 0.
\end{align*}
\item (Monotonicity) Let $A,B$ denote the two elements of $\cal F$ with $A \subset B$ then $$\Pr(A) \leq  \Pr(B).$$ 
\textit{Proof:} Apply Axiom 3 to two disjoint sets $A_1= A, A_2=A^c \cap B$ to get
\begin{align*}
 \Pr(A_1) + \Pr(A_2) &= \Pr(A_1 \cup A_2)\\
 \Pr(A) + \Pr(A^c \cap B) &= \Pr(B)
\end{align*}
Since by Axiom 1, $\Pr(A^c \cap B) \geq 0$, we have $$\Pr(A) \leq  \Pr(B).$$ 
\item (Complement rule) Let $A$ be an event then $$\Pr(A) + \Pr(A^c) =1.$$ 
\textit{Proof:} Apply Axiom 3 to two disjoint sets $A_1= A, A_2=A^c$ to get
\begin{align*}
 \Pr(A_1) + \Pr(A_2) &= \Pr(A_1 \cup A_2)\\
 \Pr(A) + \Pr(A^c) &= \Pr(\Omega)
\end{align*}
Since by Axiom 2, $\Pr(\Omega) =1$, so we are done. 

\item (Union rule) Let $A,B$ be events then $$\Pr(A \cup B) +  \Pr(A \cap B) = \Pr(A) + \Pr(B).$$ 
\textit{Proof:} Exercise!  
\end{enumerate}

\begin{lemma*}
\label{lem:sigma-monotonic}
Let $A_1 , A_2 , \ldots$ be a sequence of events and let $A = \cup_{n=1}^{\infty} A_n$, then \[\Pr(A) = \lim_{n \to \infty} \Pr(A_n).\]
\end{lemma*}
\begin{proof}
Let $A = A_1 \cup (A_2\setminus A_1) \cup (A_3 \setminus A_2) \ldots$ which is a disjoint union (draw Venn diagrams!). From proof of Monotonicity rule above, note that $$\Pr(A_{i+1} \setminus A_i)  = \Pr(A_{i+1}) - \Pr(A_i).$$ Apply Axiom 3 to the disjoint union presentation of A to get
\begin{align*}
\Pr(A) &=  \Pr(A_1 \cup (A_2\setminus A_1) \cup (A_3 \setminus A_2) \ldots)\\
       &=  \Pr(A_1) + \Pr(A_2\setminus A_1) + \Pr(A_3 \setminus A_2) \ldots\\
       &=  \Pr(A_1) + (\Pr(A_2) - \Pr(A_1)) + (\Pr(A_3) - \Pr(A_2)) \ldots\\
       &=  \lim_{n \to \infty} \Pr(A_n)
\end{align*}
\end{proof}
Let us see three important classes of examples.

\begin{example}
\label{exmpl: discset}
Let $\Omega=\{\omega_1,\omega_2,\ldots\}$ be a countable/finite set and let $f:\Omega \to [0,1]$ be a function with the property 
  \[\sum_{i=1}^{\infty} f(\omega_i) = 1.\]
Let $\cal F$ be the set of all subsets of $\Omega$. Check that $\cal F$ is a $\sigma$-algebra.
Let $E$ be any element of $\cal F$, define \[\Pr(E) := \sum_{\omega \in E} f(\omega).\]
Now check the the three axioms. The first two are straightforward. The last axiom requires some real analysis. 

Here are some examples of $f$:
\begin{enumerate}
\item (Bernoulli distribution) Set $\Omega=\{0,1\}$ and let $p$ be a real number between 0 and 1. Let $f(1) = p$ and $f(0) = 1-p$.
\item (Binomial distribution) For a positive integer $n$, set $\Omega=\{0,1,2,3,\cdots,n\}$. Let a real number $p$ between 0 and 1 be given. Then let $$f(k) = \binom{n}{k} p^k (1-p)^{n-k}.$$
\item (Geometric distribution) Set $\Omega=\mathbb{Z}_{\geq 0}$. For a real number $p$ between 0 and 1, let $$f(k) = p(1-p)^{k}.$$
\end{enumerate}

\end{example}
Example \ref{exmpl: discset} is the setup of discrete probability theory. Coin tosses, and rolling dice experiments fit into the above framework since the sample space of outcomes is a finite set in these cases.


\begin{example}
\label{exmpl: contprob}
Let $\Omega=\mathbb{R}$ and let $\cal F$ be the smallest $\sigma$-algebra that contains all intervals of the form $(a,b]$ for all reals $a,b$. For any non-negative continuous function $f:\mathbb{R} \to [0,1]$ such that \[\displaystyle \int_{-\infty}^{\infty} f(x)\, dx = 1,\] we define \[\Pr\{\left(a,b\right]\} =  \int_a^b f(x)\, dx\]
Note that the proof of axiom 3 is highly technical.

Here are some examples of $f$:
\begin{enumerate}
\item (Uniform distribution) Let $f(x) = \dfrac{1}{b-a} \text{ for  } a < x < b$ and $f(x) = 0$ otherwise.
\item (Exponential distribution) For a positive real number $\lambda$, let $f(x) = \lambda e^{-\lambda x} \text{ for  } x > 0$ and $f(x) = 0$ otherwise.
\item (Normal distribution) For a real numbers $\mu,\sigma^2$, let $$f(x) = \dfrac1{\sqrt{2 \pi \sigma^2}} e^{-\dfrac{(x-\mu)^2}{2\sigma^2}}.$$
\end{enumerate}
\end{example}

Example \ref{exmpl: contprob} is the setup of the probability theory of continuous random variables. Picking a random real number in an interval, and the random time it takes for a device to break down are examples of continuous random variables.

\begin{example}
\label{exmpl: conditionalprob}
Let $(\Omega,{\cal F},\Pr)$ be a probability space and let $C$ be an element of ${\cal F}$, then we can define a new triple $(C,{\cal F}_C,\Pr_C)$ as follows:
\begin{enumerate}
\item $C$ is the sample space of the new triple.
\item ${\cal F}_C$ is the set of all subsets of $\Omega$ of the form $A \cap C$ where $A$ is in $\cal F$. Clearly any element of ${\cal F}_C$ is a subset of $C$. Prove that ${\cal F}_C$ is a $\sigma$-algebra.
\item Let $A$ be an element of ${\cal F}_C$. Define \[{\Pr}_C(A) := \dfrac{\Pr(A \cap C)}{\Pr(C)}.\]
Check that the axioms are satisfied (straightforward exercise). We quickly remark that usually we know this measure as \[{\Pr}_C(A) = \Pr(A\mid C).\]
\end{enumerate}
\end{example}

Example \ref{exmpl: conditionalprob} shows that given an event $C$ associated with a probability space, we can define a new probability space that represents ``conditional probabilities''. The probability measure ${\Pr}_{C}$ is called \emph{the conditional probability measure}.


\subsection{Random variables and their distribution}

First we define a random variable.

\begin{definition}
  Given a probability space $(\Omega,{\cal F},\Pr)$,  a random variable $X:\Omega \to \mathbb{R}$ is a function so that the subsets $\{a < X \leq b\}$ belong to $\cal F$ for any reals $a,b$.

  Given a random variable $X$ defined on a probability space $(\Omega,{\cal F},\Pr)$, define the \emph{cumulative distribution function (c.d.f)} of  $X$ as \[F_X(b) := \Pr(X \leq b).\]
Note that this means $\Pr(a < X \leq b) = F_X(b) - F_X(a).$
\end{definition}

Few quick properties of c.d.fs:
\begin{enumerate}
  \item $$\lim_{b \to \infty} F_X(b)=1, \,\,\,\lim_{b \to -\infty} F_X(b)=0.$$
  %\textit{Proof:}  \lim_{b \to \infty} F_X(b) = \lim_{b \to \infty} \Pr(X \in (-\infty,b)) =  \Pr(X \in \cup_{b}(-\infty,b)) =\Pr(X \in \cup_{b}(-\infty,b))
  \item $F_X$ is a non-decreasing function.
  \item If $F_X(x)$ is differentiable, then \[f(x) := \dfrac{dF_X}{dx}\] is called the \emph{probability density function} (or p.d.f) of $X$. Examples of p.d.f.s $f$ are given in Example \ref{exmpl: contprob}.
  \item In case $X$ is a discrete random variable, then $F_X$ is piecewise constant and if the jumps occur at $x_1,x_2,\ldots$, then the magnitude of the jump at $x_i$ is called the p.m.f $f(x_i)$, i.e. \[f(x_i): = F(x_i) - \lim_{x \to x_i^{-}} F(x).\] Note that the sum of the p.m.f values should be $1$.
\end{enumerate}

If $F_X$ is a differentiable function and $F_X' = f$, then we have \[\Pr\{a < X \leq b\} = \int_a^b f(x)\, dx.\]

Let us informally discuss the meaning of density function. \\
\textbf{What is the meaning of probability density function?} Intuitively, density is a measure of how densely something is packed in a given region. We have seen that probability assigned to a point in a continuous sample space can be zero for some random variables. So in Example \ref{exmpl: contprob} we decided to assign probability to intervals. This means instead of asking ``What is the chance that $X=x$?'', we have to settle for the question ``What is the chance that $x-\frac{\epsilon}{2} < X \leq x+\frac{\epsilon}{2}$?'' for a small error of $\epsilon$. If a random variable $X$ has p.d.f $f(x)$, then \[\Pr(x-\frac{\epsilon}{2} < X \leq x+\frac{\epsilon}{2}) \approx f(x)\epsilon\] assuming $f(x)$ is constant in the small interval. Since $\epsilon$ is the length of the interval $I=(x-\frac{\epsilon}{2},x+\frac{\epsilon}{2})$, we see that \[f(x)=\dfrac{\Pr(X \in I)}{length(I)}.\] In words, we can say the at a point $x$, $f(x)$ measures the chance at $x$ per unit length.

\subsection{Joint p.m.fs}


\subsection{Expectation}

In this chapter, we will collect facts that will be used in the upcoming chapters.

\textcolor{red}{Show sum of finite number of i.i.d Bernoullis is Binomial.}

%\textcolor{red}{Any collection of (measurable) functions of disjoint set of independent random variables is independent. This is vague; make it precise without making it technical.}
\begin{proposition}
\label{prp:disjsumindprv}
  If we pick disjoint subsets of $T$ and sum the values of i.i.d process on each subset of $T$, the resulting set of random variables in still independent.
\end{proposition}

\section{Introduction to Stochastic Processes}

When we look at the world around us, we see interesting phenomenon that changes over time. Often the variations in these processes have unknown or random causes. The theory of probability is very useful as a tool to analyze such processes and study of these processes using the tools of probability theory is called the theory of \emph{stochastic processes}. 

Stochastic processes are crucial in economics and finance, capturing the inherent randomness in markets and economic activities. From modeling stock prices using geometric Brownian motion to predicting economic growth through random walks, these processes provide powerful tools to understand and forecast complex systems. Landmark results, such as the Black-Scholes-Merton model for option pricing and the Efficient Market Hypothesis, deeply rely on stochastic processes. These models not only offer profound insights but also drive practical applications, underscoring the natural and indispensable role of randomness in economic and financial analysis.\footnote{Thanks ChatGPT.}

Let us start with the definition of a stochastic process.

\begin{definition}
  \label{def:sp}
  A stochastic process $\{X_t\}_{\{t \in T\}}$ is a collection of random variables indexed by an \textit{indexing set} $T$. The parameter $t$ is generally called \textit{time}.
\end{definition}

Please note that to specify a stochastic process, you have to specify a set $T$ (indexing set) and then define a collection of random variables $X_t$ for each $t$ in $T$. In order to understand this definition, we will now see many natural examples.

\begin{example}
\label{exmpl: simpleCointoss}
Suppose a coin is tossed forever. Let $T=\mathbb{N}$ denote the set of all natural numbers. Let $N_k$ denote the number of tails in the $k$th toss for each natural number $k$. Note that $N_k$ is either $0$ or $1$. Now $\{N_k\}_{\{k \in T\}}$ is a stochastic process.
All the random variables that make up this process are independent and identically distributed. So this is an example of an \emph{i.i.d process}.
\end{example}


\begin{example}
\label{exmpl: totalnumberoftailsCointoss}
Suppose a coin is tossed forever. Let $T=\mathbb{N}$ denote the set of all natural numbers. Let $S_k$ denote the number of tails in the first $k$ tosses for each natural number $k$. Note that $S_k \in \{0,1,2,3,\cdots,k\}$. Now $\{S_k\}_{\{k \in T\}}$ is a stochastic process.
This stochastic process is an example of a \emph{discrete time Markov chain} which is the focus of Section \ref{sec:DTMC}. Note that this stochastic process takes discrete values (hence 'chain') and the indexing set is also discrete.

This example relates to the previous example since $S_k = N_1 + N_2 + \ldots + N_k$.
\end{example}

\begin{example}
\label{exmpl:ACs}
Suppose we stand at the MSE entrance and keep track of the ACs that are taken out of MSE for repair. Let $T=[0,\infty)$ denote the set of all non-negative real numbers. Let $A_t$ denote the number of ACs that have gone for repair in the the interval $[0,t]$ for each $t \in T$ with $A_0=0$. Note that $A_t$ is a non-negative integer. Now $\{A_t\}_{\{t \in T\}}$ is a stochastic process. 

This stochastic process is an example of a \emph{continuous time Markov chain}. This stochastic process takes discrete values (hence `chain') but the indexing set is not discrete. We will study this in detail in Section \ref{sec:CTMC}.

Interestingly, we can obtain another stochastic process from $\{A_t\}_{\{t \in T\}}$. If we assume that atmost $1$ AC is carried out at any instant of time, then define $T_k$ as the time elapsed between the $k$th AC and $k+1$th AC being carried out. This produces a stochastic process of `waiting times'
$\{T_k\}_{\{k \in \mathbb{N}\}}$. If the stochastic process of waiting times is an i.i.d process with an exponential distribution, then the continuous time Markov chain is called a \emph{Poisson process} and it is the focus of the Section \ref{sec:PP}. 
\end{example}

\begin{example}
  \label{exmpl:Martingale}
Let $T$ be the set of natural numbers. A gambler's fortune $X_n$ after playing the $n$th betting game gives us a stochastic process $\{X_n\}_{\{n \in T\}}$. If we assume all the betting games are fair games, then we get a \emph{Martingale} process which will be studied in \ref{sec:Mart}. 
\end{example}

\begin{example}
\label{exmpl:StockPrices}
Suppose you are very interested in a particular stock. Let $T=[0,\infty)$ denote the set of all non-negative real numbers. Let $P_t$ denote the stock price at time $t$ for each $t \in T$. Note that $P_t$ will be considered to be a real number and we will plot the stock price chart as a continuous function (when considered over very long periods of time). Now $\{P_t\}_{\{t \in T\}}$ is a stochastic process.
\end{example}

Recall that while studying the theory of probability, we start with an experiment and then collect all possible outcomes of the experiment into a set called the \emph{sample space}, denoted by $\Omega$. An outcome is usually denoted by the greek letter $\omega$. Practically speaking, these outcomes are randomly realized when we perform the experiment. We measure how random the outcomes are by assigning probabilities to these outcomes (either intuitively or guided by statistical inferences from real world data). Any function of these random outcomes will be random and are usually termed as \emph{random variables}. In terms of mathematical symbols, a function $X: \Omega \to \mathbb{R}$ is a random variable. 

The examples above contained a real-life experiment we wished to model. However, it might only sometimes be possible to list the experiment's outcomes in the above examples. For instance, in the case of stock prices, the experiment is the \emph{the processes of the entire world!!}. The outcomes of this experiment could range anywhere from individual emotions to global policies. It is not clear what the sample space would be in this case. At any rate, that should not stop us from studying the behaviours of stocks. In this course, we often ignore the sample space point of view for computation purposes and work directly with random variables. 

However from the point of view of conceptual understanding, the sample space point of view clarifies the nature of a stochastic process. So let us consider Example \ref{exmpl: totalnumberoftailsCointoss}. Since, in this case, it is not hard to describe the sample space, it is a useful example to understand the nature of a stochastic process. 

\begin{example}
   Suppose a coin is tossed forever. In this case, the a random outcome of this experiment is an infinite list of heads and tails. Let us write collect all these outcomes and write the set formally as \[\Omega = \{\omega = (\omega_1,\omega_2,\ldots)| \omega_i \in \{H,T\}\text{ for all }i\}.\] 
   An example outcome is an infinite string of tosses \[\omega = (H,T,T,H,T,H,T,T,T,T,\ldots)=HTTHTHTTTT\ldots\] where all the tosses are tails from the seventh toss onwards. Note that we also suppress the commmas and the parantheses and simply write the infinite list as an infinite string.

   Let $T=\mathbb{N}$ denote the set of all natural numbers. Let $S_k$ denote the number of tails in the first $k$ tosses for each natural number $k$. Clearly each $S_k$ is a random variable, i.e. $S_k:\Omega \to \mathbb{R}$. For instance, consider the outcome $\omega$ considered earlier and fix $k$ as $10$. The value of \[S_{10}(\omega) = S_{10}(HTTHTHTTTT\ldots) = 10.\] In fact, can you see that \[S_k(\omega) = k-3 \,\,\,\,\,\,\,\, \text{ for }k \geq 7?\]

   So we see that the stochastic process $S$ is a function of time ($k$) and the random outcome ($\omega$) of the experiment. All the sources of randomness is captured in $\omega$. Once you fix $\omega$, the sequence $\{S_k(\omega)\}_{\{k \in \mathbb{N}\}}$ is a deterministic process. In our example if we fix $\omega = (H,T,T,H,T,H,T,T,T,T,\ldots)=HTTHTHTTTT\ldots$, the sequence is $(0,1,2,2,3,3,4,5,6,7\ldots)$.

   The summary of the discussion is that if you fix omega, the stochastic process is a deterministic process and if you fix time index $k$ the stochastic process at that instant of time returns a random variable $S_k$.
 \end{example} 

Stochastic processes studied in this text have nice properties described below.

\begin{definition}
\,
  \begin{enumerate}
  \item Given a stochastic process $\{X_t\}_{\{t \in T\}}$, a difference random variable $X_b - X_a$ for $b > a$ (in $T$) is called an \emph{increment}. The increment is the net change in the value of the process in the interval $[a,b]$ contained in $T$. We say that $X_b - X_a$ is \emph{the increment associated to the interval} $[a,b]$.
  \item A stochastic process $\{X_t\}_{\{t \in T\}}$ has the \emph{stationary increment property} if the distribution of the increment random variable associated to any interval $[t+h,t]$ in $T$ is purely a function of $h$ and does not depend on $t$. In other words, the distribution $X_{t+h} - X_t$ depends only on $h$ and not on $t$.
  \item A collection of intervals of the form $[t_0,t_1], [t_1,t_2], [t_2,t_3],\ldots, [t_{k-1},t_k]$ for some integer $k$ will be called \emph{successive}.  
  \item A stochastic process $\{X_t\}_{\{t \in T\}}$ has the \emph{independent increment property} if the increments associated to for any collection of successive intervals are independent random variables.
  \end{enumerate}
\end{definition}

Let us see an immediate example and a non-example.

\begin{example}
  The stochastic process $\{S_k\}_{\{k \in \mathbb{N}\}}$ in Example \ref{exmpl: totalnumberoftailsCointoss} has both stationary and independent increments. Let us prove these claims.\\
  First, we show that the process has \emph{stationary increments.} Since time is discrete we will use the standard symbol $k$ instead of $t$. For $k,h \in \mathbb{N}$, consider the distribution of $$S_{k+h} - S_k = N_{k+1} + N_{k+2} + \ldots + N_{k+h}.$$ Since $N_k$ form a i.i.d Bernoulli($p$) process, the sum of $h$ random variables is distributed as Binomial($h,p$). Thus the r.v. $S_{k+h} - S_k$ is distributed as Binomial($h,p$). Clearly this is independent of $k$. Thus we have stationary increments.\\
  Next, we show that the process has \emph{independent increments.} Since time is discrete we will use the standard symbol $k$ instead of $t$. For any collection of successive intervals $[k_0,k_1], [k_1,k_2], [k_2,k_3],\ldots, [k_{l-1},k_l]$, we have to show that increments associated to the intervals are independent random variables. But note that the increment associated to the interval $[k_0,k_1]$ is \[S_{k_1} - S_{k_0} = N_{k_0+1} + N_{k_0+2} + \ldots + N_{k_1}.\] Note that this increment is the sum of the independent random variables $N_i$ in the interval $(k_0,k_1]$. Since the successive intervals $(k_i,k_{i+1}]$ are disjoint, the increments in the successive intervals are sum of i.i.d processes on disjoint subsets of $T$. So by Proposition \ref{prp:disjsumindprv}, the increments are independent. 
\end{example}

\begin{example}
  The stochastic process $\{N_k\}_{\{k \in \mathbb{N}\}}$ in Example \ref{exmpl: simpleCointoss} has stationary increments and but not independent increments. Let us prove these claims.\\
  First, we show that the process has \emph{stationary increments.} Since time is discrete we will use the standard symbol $k$ instead of $t$. For $k,h \in \mathbb{N}$, consider the distribution of $$D = N_{k+h} - N_k.$$ Since $N$ is an i.i.d Bernoulli($p$) process, the difference random variable has a pmf supported on $\{1,0,-1\}$ and the pmf is \[p_D(1) = \Pr\{N_{k+h}=1, N_k=0\}=p(1-p) = p_D(-1) , p_D(0) = p^2 + (1-p)^2. \] Thus the r.v. $S_{k+h} - S_k$ is distributed as Binomial($h,p$). Clearly this is independent of $k$. Thus we have stationary increments.\\
  Next, we show that the process has \emph{independent increments.} Since time is discrete we will use the standard symbol $k$ instead of $t$. For any collection of successive intervals $[k_0,k_1], [k_1,k_2], [k_2,k_3],\ldots, [k_{l-1},k_l]$, we have to show that increments associated to the intervals are independent random variables. But note that the increment associated to the interval $[k_0,k_1]$ is \[S_{k_1} - S_{k_0} = N_{k_0+1} + N_{k_0+2} + \ldots + N_{k_1}.\] Note that this increment is the sum of the independent random variables $N_i$ in the interval $(k_0,k_1]$. Since the successive intervals $(k_i,k_{i+1}]$ are disjoint, the increments in the successive intervals are sum of i.i.d processes on disjoint subsets of $T$. So by Proposition \ref{prp:disjsumindprv}, the increments are independent. 
\end{example}

Suppose $N(t)$ is a process valued in whole numbers and $t \in \mathbb{R}$. Further if $N(t)$ has independent increment property and the distribution of the increment $N(t+s)-N(t) \sim \text{Poisson}(\lambda s)$, then $N(t)$ is called a \emph{Poisson point process}. Note that this means $N(\omega)$ is an increasing piecewise constant function.

Suppose $W(t)$ is a process valued in real numbers, $t \in \mathbb{R}$ and $W(\omega)$ is a continuous function. Further if $W(t)$ has independent increment property and the distribution of the increment $W(t+s)-W(t) \sim \text{Normal}(0,s)$, then $W(t)$ is called a \emph{Weiner process}.

\newpage

\section{Discrete time Markov Chains}
\label{sec:DTMC}

For the purposes of this chapter, a discrete set is a set whose elements can be written as a finite or infinite list. For instance, $\mathbb{Z},\mathbb{Z}_{\geq 0}\mathbb{N}$ are discrete sets. \footnote{The mathematically accurate terminology is `countable sets'. The precise definition is: $T$ is a countable set if $T$ is in bijection with natural numbers.}

\begin{definition}
  \label{defn:DTMC}
A stochastic process $\{X_n\}_{\{n \in \mathbb{W}\}}$ with $X_n$ valued in a discrete set $D$ is called a \textit{discrete time Markov chain}(DTMC) if \[\Pr\{X_n=a_n\mid X_{n-1}=a_{n-1},X_{n-2}=a_{n-2},\cdots,X_{1}=a_{n-1}\} = \Pr\{X_n =a_n \mid X_{n-1}=a_{n-1}\}\]for all whole numbers $n$ and for all $a_1,a_2,\cdots,a_{n-1},a_n\in D$.\\
A probability of the form $\Pr\{X_n =a_n \mid X_{n-1}=a_{n-1}\}$ is called a \textit{transition probability}. If $\Pr\{X_n =i \mid X_{n-1}=j\}$ does not depend on $n$, then we say that the DTMC is homogenous. 
\end{definition}


We will only consider homogenous DTMCs. We start with a nice example of a DTMC.
\begin{example}
You walk into a casino with Rs.$2000$ to play a fair betting game. You can win or lose Rs. $1000$ per game. You plan to play the game until you hit Rs.$3000$ for the first time and then take your winnings. Let $X_n$ denote the amount of money you have at the end of the $n$th game. Note that the range of the random variable $X_n$ is $\{0,1000,2000,3000\}$. Note that outcome every game is independent of outcomes of the rest of the games.
\begin{align*}
\Pr\{X_n = a_n \mid X_{n-1}=a_{n-1},X_{n-2}=a_{n-2},\ldots\} &= \dfrac{\Pr\{X_n = a_n, X_{n-1}=a_{n-1},X_{n-2}=a_{n-2},\ldots\}}{\Pr\{X_{n-1} = a_{n-1},X_{n-2}=a_{n-2},\ldots\}}\\
&= \dfrac{\Pr\{X_n = a_n, X_{n-1}=a_{n-1},X_{n-2}=a_{n-2},\ldots\}}{\Pr\{X_{n-1} = a_{n-1},X_{n-2}=a_{n-2},\ldots\}}\\
\end{align*}
We can represent this data by a `chain'.
/*insert figure*/
\end{example}


\begin{example}
  \label{exmpl:DTMCcointoss}
Suppose a coin is tossed forever. Let $S_k$ denote the number of tails in the first $k$ tosses for each natural number $k$. Note that $S_k$ is a whole number. Now we prove the stochastic process $\{S_k\}_{\{k \in T\}}$ is a Markov chain.
Let $N_k$ denote the number of tails in the $k$th toss and let $S_k = N_1 + N_2 + \ldots + N_k$.
\end{example}

\begin{definition}
\label{defn:probDTMC}
Let $\{X_n\}$ be a homogenous DTMC with countable, ordered set $S$ of states. Let $n$ be any natural number, define the $n$-step transition probability matrix $P^{(n)}$, whose rows and columns are labelled by $S$ in the same order, as\[P^{(n)}_{ij} := \Pr\{X_{k+n}=i \mid X_k=j\}.\] We will denote the one-step transition probability matrix (t.p.m) by $P=P^{(1)}$.
\end{definition}

\begin{theorem}
  \label{thm:CK}
  Let $\{X_n\}$ be a DTMC with set of orderd set of states $S$ and t.p.m $P$. Then 
                      \[P^{(n)}=P^n.\] where $P^n$ is the matrix $P$ raised to the power of $n$.
\end{theorem}
\begin{proof}
  By definition $P^{(1)}=P$, suppose we have shown $P^{(n-1)} = P^{n-1}$
  We will show the $ij$th entry match on both sides.
  \begin{align*}
  P^{(n)}_{ij} &= \Pr\{X_{n}=i \mid X_0=j\} 
  \end{align*}
\end{proof}
\newpage

\section{Poisson point process}
\label{sec:PP}

\begin{definition}
    \label{def:PoissonProcess}
   Let $\{N(t) \mid t \in [0,\infty)\}$ be a stochastic process with $N(t) \in \{0,1,2,3,\ldots\}$. The stochastic process $N(t)$ is called a \emph{Poisson point process} if 
   \begin{enumerate}
   \item $N(0)=0.$
   \item $N(t+s)-N(s)\sim \text{ Poisson}(\lambda t)$ for some positive real number $\lambda$ and all reals $s,t$.
   \item $N(t)$ has the independent increment property.
   \end{enumerate}
\end{definition}

Note that the Poisson point process is a continuous time process but $N(t)$ takes values from a discrete set.

\begin{definition}
\label{def:poissterms}
Let $T_i$ denote the first time $t$ when $N(t)=i$ for $i=0,1,2,3,\cdots$ and the random variables are called \emph{time of arrivals}. The random variables $W_{i+1} := T_{i+1} - T_{i}$, for $i=0,1,2,3,\cdots$ are called \emph{interarrival times} (or \emph{waiting times}). 
\end{definition}

The following theorem establishes few basic properties of Poisson point processes.

\begin{theorem}
\label{thm:basic facts}
The following facts are immediate:
\begin{enumerate}
\item $N(t)$ has the stationary increment property.
\item Let $n$ be a natural number. The interarrival times $\{W_1,W_2,W_3,\ldots,W_{n}\}$ are independent random variable and each random variable has Exponential($\lambda$) as its distribution.
\item The distribution of `time of arrival' $T_n$ is Erlang($n,\lambda$).  
\end{enumerate}
\end{theorem}
\begin{proof}
\,
\begin{enumerate}
\item Since by second property in the definition of Poisson process $N(t+s) - N(s) \sim \text{ Poisson}(\lambda t)$, we see that the distribution of the increment is not dependent on $s$.
\item We will do it for the case of two variables $W_1,W_2$. The general proof is similar. Clearly the interarrival times are non-negative valued. So we will consider $w_1,w_2$ as non-negative real numbers.
{\small
\begin{align*}
\Pr\{W_2 > w_2 \mid W_1 = w_1\} &= \Pr\{T_2 > T_1 + w_2 \mid T_1 = w_1\}\\
&= \Pr\{T_2 > w_1 + w_2 \mid T_1 = w_1\}\\
&= \Pr\{N(w_1 + w_2)-N(w_1)= 0 \mid N(w_1)-N(0)=1, N(t)-N(0)=0 \text{ for } t < w_1 \}\\
&= \Pr\{N(w_1 + w_2)-N(w_1)= 0\}\\
&= e^{-\lambda w_2}
\end{align*}}
The first equality follows from definition of interarrival times and the third equality follows from the definition of arrival times. The fourth equality follows from independent increment property since interval $(w_1,w_1+w_2]$ is disjoint from $(0,t]$ for all $t \leq w_1$. The fifth equality follows from the second property of the Poisson process, i.e. the distribution of $N(w_1 + w_2)-N(w_1)$ is Poisson($\lambda w_2$).

Now we note that 
\[\Pr\{ W_2 > w_2 \mid W_1 = w_1\} = e^{-\lambda w_2}.\] Thus $W_1,W_2$ are independent random variables and further  \[\Pr\{W_2 > w_2\} = e^{-\lambda w_2}\] for $w_2 > 0$. Thus $W_2\sim$ Exponential($\lambda$).

A similar calculation shows 
\begin{align*}
\Pr\{W_1 > w_1\} &= \Pr\{T_1 > w_1\}\\
&= \Pr\{ N(w_1)-N(0)=0\}\\
&= e^{-\lambda w_1}
\end{align*}
Thus $W_1\sim$ Exponential($\lambda$).

\item Since $T_n = W_n+W_{n-1}+\ldots+W_1$ and the sum of $n$ i.i.d Exponential($\lambda$) variables is Erlang($n,\lambda$). Note that the pdf of Erlang($n,\lambda$) is 
\[f(x) = \dfrac{\lambda e^{-\lambda x} (\lambda x)^{n-1}}{(n-1)!} \,\, \text{ for x > 0}.\]
\end{enumerate}
\end{proof}
The Erlang distribution is the special case of the Gamma distribution. You are supposed to memorise the p.d.f of Gamma distribution. You should know the mean, median, variance and mode of the Gamma distribution.

It turns out that any calculation in Poisson process theory is executed by rewriting events in terms of increments of disjoint intervals. So let us setup some notations and a dictionary to aid our calculations:

\begin{definition}
    \label{defn:incrementnotation}
    Let $N(t)$ be a Poisson point process with rate $\lambda$, then for $0 < a < b < c < d < \ldots$ let us write \[ N[a,b,c,d,e\ldots] = [p,q,r,s\ldots]\] to mean \begin{align*}
                              N(b)-N(a)&=p\\
                              N(c)-N(b)&=q\\
                              N(d)-N(c)&=r\\
                              N(e)-N(d)&=s\\
                              .&=.\\
                              .&=.\\\end{align*}
\end{definition}

A dictionary of equivalent events that translates events of arrival times to events of independent increments of the Poisson process is shown in Table \ref{table:dictionary}.

\begin{table}[]
\small
\begin{tabular}{|l|l|}
\hline
{\bf Events in terms of (inter-)arrival times and process}             & {\bf Events in terms of increments of disjoint intervals} \\
\hline
$\{T_1 > t_1\}$                                                  & $\{N[0,t_1]=[0]\}$ \\ \hline  
$\{T_1 = t_1, N(t)=2 \}$                                         & $\{N[0,s,t_1,t]=[0,1,1] \text{ for all } s < t_1 \}$  \\ \hline
$\{t_1 \leq T_1 < t_1 +dt_1,t_2 \leq  T_2 < t_2 +dt_2, N(t)=3\}$ & $\{N[0,t_1, t_1+dt_1,t_2,t_2+dt_2,t]=[0,1,0,1,1]\}$  \\
\hline
\end{tabular}
\caption{Few examples of moving between equivalent events.}
\label{table:dictionary}
\end{table}

In order to cut down on rigorous mathematical arguments, we will use the following (intuitive) formulae involving infinitesimals ($dx, dt,\ldots$): 

\begin{enumerate}
\item Let $X$ be a random variable with p.d.f $f$, then \[f(x)\, dx = \Pr\{x < X \leq x+dx\}.\] 
\item Let $X_1,X_2\ldots,X_n$ be a collection of $n$ random variables with joint p.d.f $f$, then {\small\[f(x_1,x_2,\ldots,x_n)\, dx_1\, dx_2\,\ldots dx_n = \Pr\{x_1 < X_1 \leq x_1+dx_1,x_2 < X_2 \leq x_2+dx_2,\ldots ,x_n < X_n \leq x_n+dx_n\}.\] }
\item We will use $f(t)+dt = f(t)$ only if $f(t) \neq 0$ and $dt + O(dt^2) = dt$. For example $e^{-\lambda dt} = 1 -\lambda dt + O(dt^2) = 1-\lambda dt = 1$
\end{enumerate}

\begin{remark}
Strictly speaking the above formulae are ridiculous and can easily confuse a careless novice. So one needs to take care while using infinitesimals. Learn from discussions in class and chat with TAs if you are confused. If at any step you feel worried, then go back to computing cdfs and differentiate cdfs to get pdfs.
\end{remark}

Let us see an example of how to use the above intuitive rules.

\begin{example}
Let $N(t)$ be a Poisson process with rate $\lambda$, then the joint distribution of arrival times $T_1, T_2$ is computed below. Let $0 < t_1 < t_2$, then
\begin{align*}
f_{T_1,T_2}(t_1,t_2)dt_1\,dt_2 &= \Pr\{t_1 < T_1 \leq t_1+dt_1,t_2 < T_2 \leq t_2+dt_2\}\\
                               &= \Pr\{N[0,t_1,t_1+dt_1,t_2,t_2+dt_2]=[0,1,0,1]\}\\
                               &= (e^{-\lambda t_1})(e^{-\lambda dt_1}\lambda dt_1)(e^{-\lambda (t_2-t_1-dt_1)})(e^{-\lambda dt_2}\lambda dt_2)\\
                               &= (e^{-\lambda t_1})(e^{-\lambda dt_1}\lambda dt_1)(e^{-\lambda (t_2-t_1-dt_1)})(e^{-\lambda dt_2}\lambda dt_2)\\
                               &= e^{-\lambda t_2} \lambda^2 dt_1 \, dt_2.
\end{align*}
So comparing we see that for $0 < t_1 < t_2$, we have \[f_{T_1,T_2}(t_1,t_2) = e^{-\lambda t_2} \lambda^2.\]The joint pdf vanishes for any other pair $t_1,t_2$.
\end{example}

Here is a list of exercises for you to practice.

\begin{lemma}
Let $N(t)$ be a Poisson process with rate $\lambda$, then 
\begin{align*}
\Pr\{ N[0,t_1,t_1+dt_1]=[0,1]\} &= e^{-\lambda t_1} \lambda \, dt_1\\
\Pr\{N[0,t_1,t_1+dt_1,t]=[0,1,0]\} &= e^{-\lambda t} \lambda \, dt_1\\
\Pr\{N[0,t_1,t_1+dt_1,t]=[0,1,1]\} &= e^{-\lambda t} \lambda^2 (t-t_1)\, dt_1\\
\Pr\{N[0,t_1,t_1+dt_1,t_2,t_2+dt_2]=[0,1,0,1]\} &= e^{-\lambda t_2} \lambda^2 \, dt_1,dt_2\\
\Pr\{N[0,t_1,t_1+dt_1,t_2,t_2+dt_2,t]=[0,1,0,1,0]\} &= e^{-\lambda t} \lambda^2 \, dt_1,dt_2\\
\Pr\{N[0,t_1,t_1+dt_1,t_2,t_2+dt_2,t]=[0,1,0,1,1]\} &= e^{-\lambda t} \lambda^3 (t-t_2) \, dt_1,dt_2
\end{align*}
For $k > 1$ $\Pr\{N[dt]=[k]\}=0$.  
\end{lemma}

\begin{example}
\label{example:Nuniform}
Let us calculate a couple of related distributions.
\begin{enumerate}
\item Let $n \geq 1$. The conditional p.d.f \[f_{T_1 \mid N(t)}(s \mid N(t)=n)=\frac{n}{t} \left(1-\dfrac{s}{t}\right)^{n-1}\] for $0<s<t$ and $0$ otherwise. This tells us that if it is known a point has arrived in the interval $[0,t]$, then the arrival time is uniformly distributed in the interval $[0,t]$.
\item The conditional p.d.f \[f_{T_2 \mid T_1, N(t)}(t_2 \mid T_1=t_1, N(t)=n)=\dfrac{n-1}{t-t_1}\left(1- \dfrac{t_2-t_1}{t-t_1}\right)^{n-1}, \,\,\, t_1 < t < t_2 \] for $t_1<t_2<t$ and $0$ otherwise.
\end{enumerate}
\begin{proof}
\begin{enumerate}
\item Assume $0 < s< t$, 
\begin{align*}
f_{T_1 \mid N(t)}(s \mid N(t)=n)\, ds &= \Pr\{s < T_1 < s+ds | N(t)=n\}\\
                                      &= \dfrac{\Pr\{s < T_1 < s+ds , N(t)=n\}}{\Pr\{N(t)=n\}}\\
                                      &= \dfrac{\Pr\{N[0,s,s+ds,t]=[0,1,n-1]\}}{\Pr\{N(t)=n\}}\\
                                      &= \dfrac{e^{-\lambda t}(\lambda \, ds) \frac{(\lambda(t-s))^{n-1}}{(n-1)!}}{e^{-\lambda t}\frac{(\lambda t)^n}{n!}}\\
                                      &= \frac{n}{t} \left(1-\dfrac{s}{t}\right)^{n-1}ds
\end{align*}
Clearly if $s > t$, \[f_{T_1 \mid N(t)}(s \mid N(t)=1) \, ds = \Pr\{s < T_1 < s+ds | N(t)=1\} = 0.\]
\item Assume $t_1 < t_2 < t$,
\begin{align*}
f_{T_2 \mid T_1, N(t)}(t_2 \mid T_1=t_1, N(t)=n)\, dt_2 &= \Pr\{t_2 < T_2 < t_2+dt_2 |T_1=t_1, N(t)=n\}\\
                                      &= \dfrac{\Pr\{t_2 < T_2 < t_2+dt_2 , N(t)=n \mid T_1=t_1\}}{\Pr\{N(t)=n \mid T_1=t_1\}}\\
                                      &= \dfrac{\Pr\{t_2 < T_2 < t_2+dt_2 , N(t) - N(t_1)=n-1 \mid T_1=t_1\}}{\Pr\{N(t) - N(t_1)=n-1 \mid T_1=t_1\}}\\
                                      &= \dfrac{\Pr\{t_2 < T_2 < t_2+dt_2 , N(t) - N(t_1)=n-1\}}{\Pr\{N(t) - N(t_1)=n-1\}}\\
                                      &= \dfrac{\Pr\{N[t_1,t_2,t_2+dt_2,t]=[0,1,n-2]\}}{\Pr\{N(t)- N(t_1)=n-1\}}\\
                                      &= \dfrac{e^{-\lambda (t-t_1)}(\lambda \, dt_2) \left(\frac{(\lambda (t-t_2))^{n-2}}{(n-2)!}\right)}{e^{-\lambda (t-t_1)}\frac{(\lambda(t-t_1))^{n-1}}{(n-1)!}}\\
                                      &= \dfrac{n-1}{t-t_1} \left( 1 - \dfrac{t_2-t_1}{t-t_1}\right)^{n-2} \, dt_2
\end{align*}
\end{enumerate}
\end{proof} 
\end{example}

From the above examples, we see that for $T_1$ is uniformly distributed in $[0,t]$ given $N(t)=1$. If it is given that $N(t) \geq 2$, then the first arrival time $T_1$ is not uniformly distributed in $[0,t]$.


\begin{exercise}A couple of exercises for the reader:
\begin{enumerate}
    \item Show that $$f_{T_1|N(t)}(s \mid N(t)=0) = \lambda e^{-\lambda(s-t)} \,\, \text{for }s \geq t$$ and it is zero elsewhere. 
    \item Show that for $n > 0$, \[\mathbb{E}(T_1 \mid N(t)=n) = \dfrac{t}{n+1}.\]
    \item Compute \[\mathbb{E}(T_1 \mid N(t)=0).\]
    \item Compute $\mathbb{E}(T_2 \mid T_1,N(t))$.
\end{enumerate}
\end{exercise}

Supposing we knew that $N(t)=n$, then what is the distribution of the arrival times $T_1,T_2,\ldots,T_n$? The answer is interesting. 
\begin{theorem}
The conditional pdf of interarrival times $T_1,T_2,\ldots,T_n$ given $N(t)=n$ is given by: For $0<t_1<t_2<\ldots< t_n < t$
\[f(t_1,t_2,\ldots,t_n\mid N(t)=n) = \dfrac{n!}{t^n}\]
Elsewhere the pdf is zero. Note the pdf is constant (or uniform) in the region $0<t_1<t_2<\ldots< t_n < t$.
\end{theorem}
Using the techniques shown in the previous examples, this above theorem is easily proved.

A remarkable property of the Poisson process is that if split the arrivals of a Poisson process by flipping a biased coin, the two resulting processes are independent Poisson processes!! I don't know any other stochastic processes with this property. So if you want extra credit, then think about classifying all stochastic processes with this property. 
\begin{theorem}
\label{thm:splittingPoisson}
Let $N(t)$ be a Poisson process with rate $\lambda$, suppose every arrival is labelled 1 with probability $p$ and $0$ with probability $1-p$. Suppose this each arrival is independently labelled. Let $N_1(t)$ denote the number of points labelled 1 in $[0,t]$, and $N_0(t)$ denote the number of points labelled 0 in $[0,t]$. Then $N_0(t),N_1(t)$ are independent Poisson processes with rates $p\lambda$ and $(1-p)\lambda$.
\end{theorem}
\begin{proof}
It is clear that $N_0(t)+N_1(t)=N(t)$. We will use this fact freely.\\ 
Suppose there are totally $n$ arrivals. The probability that $k$ of them are labelled $1$ and $n-k$ are labelled $0$ is given by the Binomial distribution:
\begin{align*}
\Pr\{N_1(t)=k,N_0(t)=n-k \mid N(t)=n\} &= \binom{n}{k} p^k (1-p)^{n-k}\\
\dfrac{\Pr\{N_1(t)=k,N_0(t)=n-k,N(t)=n\}}{\Pr\{N(t)=n\}} &= \binom{n}{k} p^k (1-p)^{n-k}\\
\dfrac{\Pr\{N_1(t)=k,N_0(t)=n-k\}}{\Pr\{N(t)=n\}} &= \binom{n}{k} p^k (1-p)^{n-k}\\
\Pr\{N_1(t)=k,N_0(t)=n-k\} &= \binom{n}{k} p^k (1-p)^{n-k}\Pr\{N(t)=n\}\\
\Pr\{N_1(t)=k,N_0(t)=n-k\} &= \left(\dfrac{n!}{k!(n-k)!}\right) p^k (1-p)^{n-k}\left(\dfrac{e^{-\lambda t}(\lambda t)^n}{n!}\right)\\
\Pr\{N_1(t)=k,N_0(t)=n-k\} &= \left(\dfrac{e^{-p\lambda t}(p\lambda t)^k}{k!}\right)\left(\dfrac{e^{-(1-p)\lambda t}((1-p)\lambda t)^{n-k}}{(n-k)!}\right)
\end{align*}
Thus for every real $t>0$, $N_0(t),N_1(t)$ are independent random variables and they are distributed as Poisson($p\lambda$) and Poisson($(1-p)\lambda$) respectively.
\end{proof}

Another cool property of Poisson processes is that sum of two independent Poisson process is a Poisson process with sum of the rates. This will be an exercise problem. 

\subsection{Cramer-Lundberg Ruin theory}

The following section is an selective adaptation of \cite{SR05} and we advise the reader to refer to those notes. What follows is a poor imitation of those notes and at times I have shamelessly lifted a few sentences from those notes. 

In a \emph{collective risk model} there are a number of contracts for risks, like insurance against thefts, accidents, natural calamities and other adverse events. A company might be selling a collection of such contracts and we are interested in avoiding the ruin of the insurance company. 

Assume that the number of claims that appear in the interval $[0,t]$ is denoted by $N(t)$. The ith claim that appears at time $T_{i}$ causes a payment of $X_{i}$ (called the $i$th claim size). We assume that the collection of claim sizes $\{X_{i}|i \in \mathbb{Z}_{\geq 0}\}$ are independent random variables and further, we also assume that the random variables of stochastic process $N(t)$ are independent of the claim sizes $\{X_{i}|i\in\mathbb{Z}_{\geq0}\}$.

Let $t \geq 0$. The aggregate claim amount paid by the company in the interval $[0,t]$ is given by \[S(t):=\sum_{i=1}^{N(t)}X_{i}.\] 

\textcolor{red}{Expand on this exercise:}
\begin{enumerate}
\item Let $r$ be the fixed interest rate in the market. Define the discounted sum:\[S_{0}(t):=\sum_{i=1}^{N(t)}e^{-rT_{i}}X_{i}.\]Explain the meaning of $S_{0}(t)$ and the significance of this quantity.

\item Assume $N(t)$ is a Poisson point process with rate $\lambda$. If the average claim size is $\overline{X}$. Show that the expectation of $S_{0}(t)$ is $$\mathbb{E}(S_{0}(t))=\dfrac{\lambda}{r}(1-e^{-rt})\overline{X}.$$

\item Let $p(t)$ denote the premium income in the time interval $[0,t]$ and suppose the company had an initial capital of u units. Then the company's capital balance function is defined as \[U(t)=u+p(t)-S(t).\] What is the average value of $U(t)$?
\end{enumerate}

The first time t such that $U(t)<0$ is called the ruin time. \textcolor{red}{Discuss the main theorem of ruin after introducing martingales?.}

\section{Continuous time Markov Chains}
\label{sec:CTMC}


\section{Martingales}
\label{sec:Mart}

\begin{thebibliography}{9}
\bibitem{Ramasubramanian2005}
S. Ramasubramanian, \emph{Poisson Process and Insurance: An Introduction}, 2005. Available at: \url{https://www.isibang.ac.in/~statmath/ram/ASPDelhi05.pdf}.

\end{thebibliography}



\end{document}
